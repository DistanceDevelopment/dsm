[{"path":"/articles/data_format/dsm-data-formatting.html","id":"introduction","dir":"Articles > Data_format","previous_headings":"","what":"Introduction","title":"`dsm` data formatting example","text":"dsm package expects data specific format. example ’ll show get data format give explanation requirements exist. recommend getting grips fitting models dsm reading tutorial know end point look like trying grapple data. example Gulf Mexico pantropical spotted dolphins available .","code":""},{"path":"/articles/data_format/dsm-data-formatting.html","id":"prerequisites","dir":"Articles > Data_format","previous_headings":"","what":"Prerequisites","title":"`dsm` data formatting example","text":"run code , need ggplot2 sf libraries installed. can following code: Rhode Island data required downloaded : loon observations coastline dbf coastline projection coastline shapefile coastline shx transects dbf transects projection transects shapefile transects shx placed folder called data code work.","code":"install.packages(c(\"ggplot2\", \"sf\"))"},{"path":"/articles/data_format/dsm-data-formatting.html","id":"overview","dir":"Articles > Data_format","previous_headings":"","what":"Overview","title":"`dsm` data formatting example","text":"collect distance sampling data, need record (1) distance observation (along detectability covariates like weather), (2) transect currently , (3) much effort expended transect (length number visits). want fit DSM information needs expanded include transect , can build spatial model. point transects, simple always point, line transects need know position detection (equivalently, far along transect ). abstractly, need information detections effort. also need link two. dsm use three objects hold information: fitted detection function (argument ddf.obj) holds detections ignores spatial information “segments” (argument segment.data) holds chunks effort (parts transect point visits) locations. might also include environmental covariate information. table linking two (argument observation.data), making sure detection corresponding segment. image gives overview different data.frames interact, along corresponds real life situation collecting data transect. rest example goes table turn, explaining construction.","code":""},{"path":[]},{"path":"/articles/data_format/dsm-data-formatting.html","id":"detection-data","dir":"Articles > Data_format","previous_headings":"Table construction","what":"Detection data","title":"`dsm` data formatting example","text":"data requirements similar packages mrds Distance. cases, detection corresponding row. analysis using dsm additional requirements data (can auto-generated Distance recommend ensure know records link correctly). Distance need: distance : distance detection object : unique detection identifier (link observation table) size : number individuals detection (1 objects occur alone) mrds requires following extra columns (allow double observer surveys): detected : 1 detected observer 0 missed (always 1 single observer) observer : observer number (1 2) (always 1 single observer) covariates affect detectability recorded (e.g., sex weather) can included data analysis mrds Distance. model fitted, deal fitted model object dsm analysis.","code":""},{"path":"/articles/data_format/dsm-data-formatting.html","id":"segment-data","dir":"Articles > Data_format","previous_headings":"Table construction","what":"Segment data","title":"`dsm` data formatting example","text":"use term “segment” refer points point transects small chunks transect line transect case. ’ll assume ’ve already segmented lines first describing data format, go example segment line transect data. data.frame required segments needs following columns: Effort : effort expended segment (either length segment lines, number visits points) Sample.Label : unique identifier segment (engaged complicated survey, might take format like “YEAR-AREA-LINE-SEGMENT”, labels like “2020-North--15”, can useful keep track data came later). addition, environmental covariates like location relevant covariates (sea surface temperature, foliage type, altitude, bathymetry, etc) can included data.frame used spatial model.","code":""},{"path":"/articles/data_format/dsm-data-formatting.html","id":"segmenting","dir":"Articles > Data_format","previous_headings":"Table construction > Segment data","what":"Segmenting","title":"`dsm` data formatting example","text":"data lines want chop segments, section give sample R code . things work extremely dependent input data, hopefully gives template want least. jump : fluent ArcGIS QGIS recommend task software familiar first. simple guide task QGIS ArcGIS recommend MGET toolbox. example, look aerial survey seabirds coast Rhode Island, USA. Data surveys collected University Rhode Island analysed K. Winiarski, Miller, Paton, & McWilliams (2013), K. J. Winiarski, Burt, et al. (2014) K. J. Winiarski, Miller, Paton, & McWilliams (2014). transects saved shapefile “chop-” segments. start let’s plot data coastline:  code loaded sf package. package use spatial work segmenting data. tools expected GIS, though package still developed functionality always increasing. Investigating transects data loaded, can see consists data.frame extra bits (spatial information, including locations (geometry) projection (CRS)): one row per transect (total 24 transects), consists line joining start end points make transects. want can plot individual rows via plot(transects[1,]); can useful check row single line, processing needed (can tricky covered tutorial see “information” ). data looks good shape, can use st_segmentize function take transect make segments . make sure everything works correctly, need project data first. ’m using appropriate projected coordinate system (EPSG code 6348), Rhode Island State Plane. know truncation used detection function 1000m (distances collected bins bin), since ’re trying make segments approximately square, set length twice (since truncation applies either side transect), 2000m. Looking : See now row many coordinates attached , just looking first row (transect 1) comparing coordinates transects segs transects just two coordinates (start end points line). Whereas: segs 5, corresponding segment cut points. now need break rows segs multiple rows, one per segment. bit fiddly. use function provided dieghernan site . first load function (don’t worry understanding code!): can use separate segments look results: now 590 segments 1km 2km long. can check lengths using st_length function plot histogram segment lengths:  Note setting dfMaxLength argument st_segmentize giving rough guide segment length algorithm inside st_segmentize tries get segments equal length possible (note \\(x\\) axis histogram). Note also Transect column segs now duplicate entries transect multiple segments . can now create required columns dsm. First, Effort column can generated using st_length: can generate Sample.Labels. ’ll use complicated naming scheme show ’s done, one simply write segs$Sample.Label <- 1:nrow(segs) sufficient. Instead, like Sample.Label “YEAR-AREA-LINE-SEGMENT” scheme suggested . fancier ways , clarity, let’s use loop: Now can check looks right: required columns taken care , can also calculate centroids segments get locations segment use spatial model. Handily can use st_centroid one step keep data time. get warning centroids might calculated correctly latitude/longitude used. need project data first (Rhode Island State Plane) step using st_transform. Notice geometry type now POINT. can plot centroids previous map:  present, dsm package doesn’t know talk sf objects, final step need simplify segs regular data.frame, dsm can interpret. can extract coordinates centroids using st_coordinates append onto data.frame version object geometry dropped, like : can double check looks right: done. See next section link segments detections. want include spatial covariate information segment table, use (example) rerrdap obtain remotely-sensed data. situ data (.e., weather conditions recorded effort), can complicated require use summarize, see thread information deal situation.","code":"library(ggplot2) library(sf)  # coast data, just for reference coastline <- read_sf(\"data/ri_coast.shp\")  # our transect lines transects <- read_sf(\"data/ri_transects.shp\")  # now make the plot p <- ggplot() +   # geom_sf knows what to do with spatial data   geom_sf(data=coastline) +   geom_sf(data=transects, aes(colour=Transect)) +   # chop to be on a better scale   coord_sf(xlim=c(-72, -70.8), ylim=c(40.8, 41.5), expand=FALSE) +   # make the plot look simpler   theme_minimal()  print(p) transects ## Simple feature collection with 26 features and 1 field ## Geometry type: LINESTRING ## Dimension:     XY ## Bounding box:  xmin: -71.86948 ymin: 40.82944 xmax: -70.8944 ymax: 41.46521 ## Geodetic CRS:  WGS 84 ## # A tibble: 26 × 2 ##    Transect                                 geometry ##       <dbl>                         <LINESTRING [°]> ##  1        1 (-71.86948 41.29969, -71.86581 41.25891) ##  2        2  (-71.82872 41.30738, -71.82145 41.2258) ##  3        3 (-71.78805 41.31562, -71.75676 40.94846) ##  4        4 (-71.74674 41.31728, -71.71394 40.92971) ##  5        5  (-71.70589 41.3241, -71.67156 40.91612) ##  6        6 (-71.66578 41.33943, -71.62329 40.82944) ##  7        7   (-71.5435 41.36397, -71.5064 40.91516) ##  8        8  (-71.5015 41.35994, -71.45266 40.82978) ##  9        9 (-71.46131 41.37378, -71.42458 40.92496) ## 10       10   (-71.421 41.38723, -71.37562 40.83641) ## # ℹ 16 more rows # project transects transects <- st_transform(transects, 6348)  # do the segmenting segs <- st_segmentize(transects, dfMaxLength=units::set_units(2000, \"metres\"))  # transform back to lat/long segs <- st_transform(segs, 4326) transects <- st_transform(transects, 4326) segs ## Simple feature collection with 26 features and 1 field ## Geometry type: LINESTRING ## Dimension:     XY ## Bounding box:  xmin: -71.86948 ymin: 40.82944 xmax: -70.8944 ymax: 41.46521 ## Geodetic CRS:  WGS 84 ## # A tibble: 26 × 2 ##    Transect                                                             geometry ##  *    <dbl>                                                     <LINESTRING [°]> ##  1        1 (-71.86948 41.29969, -71.86826 41.2861, -71.86703 41.2725, -71.8658… ##  2        2 (-71.82872 41.30738, -71.82727 41.29106, -71.82581 41.27475, -71.82… ##  3        3 (-71.78805 41.31562, -71.78654 41.29813, -71.78505 41.28065, -71.78… ##  4        4 (-71.74674 41.31728, -71.74524 41.29967, -71.74373 41.28205, -71.74… ##  5        5 (-71.70589 41.3241, -71.70438 41.30636, -71.70288 41.28863, -71.701… ##  6        6 (-71.66578 41.33943, -71.6643 41.32185, -71.66283 41.30426, -71.661… ##  7        7 (-71.5435 41.36397, -71.542 41.34602, -71.54051 41.32807, -71.53901… ##  8        8 (-71.5015 41.35994, -71.49986 41.34227, -71.49821 41.3246, -71.4965… ##  9        9 (-71.46131 41.37378, -71.45983 41.35583, -71.45835 41.33788, -71.45… ## 10       10 (-71.421 41.38723, -71.41952 41.36946, -71.41804 41.3517, -71.41656… ## # ℹ 16 more rows st_coordinates(transects[1,]) ##              X        Y L1 ## [1,] -71.86948 41.29969  1 ## [2,] -71.86581 41.25891  1 st_coordinates(segs[1,]) ##              X        Y L1 ## [1,] -71.86948 41.29969  1 ## [2,] -71.86826 41.28610  1 ## [3,] -71.86703 41.27250  1 ## [4,] -71.86581 41.25891  1 stdh_cast_substring <- function(x, to = \"MULTILINESTRING\") {   ggg <- st_geometry(x)    if (!unique(st_geometry_type(ggg)) %in% c(\"POLYGON\", \"LINESTRING\")) {     stop(\"Input should be  LINESTRING or POLYGON\")   }   for (k in 1:length(st_geometry(ggg))) {     sub <- ggg[k]     geom <- lapply(       1:(length(st_coordinates(sub)[, 1]) - 1),       function(i)         rbind(           as.numeric(st_coordinates(sub)[i, 1:2]),           as.numeric(st_coordinates(sub)[i + 1, 1:2])         )     ) %>%       st_multilinestring() %>%       st_sfc()      if (k == 1) {       endgeom <- geom     }     else {       endgeom <- rbind(endgeom, geom)     }   }   endgeom <- endgeom %>% st_sfc(crs = st_crs(x))   if (class(x)[1] == \"sf\") {     endgeom <- st_set_geometry(x, endgeom)   }   if (to == \"LINESTRING\") {     endgeom <- endgeom %>% st_cast(\"LINESTRING\")   }   return(endgeom) } segs <- stdh_cast_substring(segs, to=\"LINESTRING\") ## Warning in st_cast.sf(., \"LINESTRING\"): repeating attributes for all ## sub-geometries for which they may not be constant segs ## Simple feature collection with 590 features and 1 field ## Geometry type: LINESTRING ## Dimension:     XY ## Bounding box:  xmin: -71.86948 ymin: 40.82944 xmax: -70.8944 ymax: 41.46521 ## Geodetic CRS:  WGS 84 ## # A tibble: 590 × 2 ##    Transect                                 geometry ##       <dbl>                         <LINESTRING [°]> ##  1        1  (-71.86948 41.29969, -71.86826 41.2861) ##  2        1   (-71.86826 41.2861, -71.86703 41.2725) ##  3        1  (-71.86703 41.2725, -71.86581 41.25891) ##  4        2 (-71.82872 41.30738, -71.82727 41.29106) ##  5        2 (-71.82727 41.29106, -71.82581 41.27475) ##  6        2 (-71.82581 41.27475, -71.82436 41.25843) ##  7        2  (-71.82436 41.25843, -71.8229 41.24212) ##  8        2   (-71.8229 41.24212, -71.82145 41.2258) ##  9        3 (-71.78805 41.31562, -71.78654 41.29813) ## 10        3 (-71.78654 41.29813, -71.78505 41.28065) ## # ℹ 580 more rows hist(st_length(segs), xlab=\"Segment lengths (m)\", main=\"\") segs$Effort <- st_length(segs) # create a dummy column that we can fill in as we go segs$Sample.Label <- NA  # set the year and area once for this data year <- 2010 area <- \"RI\"  # loop over the transect IDs for(this_transect in unique(segs$Transect)){   # how many segments in this transect?   n_segs <- nrow(subset(segs, Transect==this_transect))   # generate the n_segs labels that we need   segs$Sample.Label[segs$Transect==this_transect] <- paste(year, area, this_transect,                                                            1:n_segs, sep=\"-\") } segs ## Simple feature collection with 590 features and 3 fields ## Geometry type: LINESTRING ## Dimension:     XY ## Bounding box:  xmin: -71.86948 ymin: 40.82944 xmax: -70.8944 ymax: 41.46521 ## Geodetic CRS:  WGS 84 ## # A tibble: 590 × 4 ##    Transect                                 geometry Effort Sample.Label ##  *    <dbl>                         <LINESTRING [°]>    [m] <chr>        ##  1        1  (-71.86948 41.29969, -71.86826 41.2861)  1515. 2010-RI-1-1  ##  2        1   (-71.86826 41.2861, -71.86703 41.2725)  1515. 2010-RI-1-2  ##  3        1  (-71.86703 41.2725, -71.86581 41.25891)  1515. 2010-RI-1-3  ##  4        2 (-71.82872 41.30738, -71.82727 41.29106)  1818. 2010-RI-2-1  ##  5        2 (-71.82727 41.29106, -71.82581 41.27475)  1818. 2010-RI-2-2  ##  6        2 (-71.82581 41.27475, -71.82436 41.25843)  1818. 2010-RI-2-3  ##  7        2  (-71.82436 41.25843, -71.8229 41.24212)  1818. 2010-RI-2-4  ##  8        2   (-71.8229 41.24212, -71.82145 41.2258)  1818. 2010-RI-2-5  ##  9        3 (-71.78805 41.31562, -71.78654 41.29813)  1948. 2010-RI-3-1  ## 10        3 (-71.78654 41.29813, -71.78505 41.28065)  1948. 2010-RI-3-2  ## # ℹ 580 more rows # save the line version of segs for plotting later segs_lines <- segs  # project segs segs <- st_transform(segs, 6348)  # find centroids segs <- st_centroid(segs) ## Warning: st_centroid assumes attributes are constant over geometries # project back to lat/long segs <- st_transform(segs, 4326)  # how does that look? segs ## Simple feature collection with 590 features and 3 fields ## Geometry type: POINT ## Dimension:     XY ## Bounding box:  xmin: -71.86887 ymin: 40.83823 xmax: -70.89506 ymax: 41.45646 ## Geodetic CRS:  WGS 84 ## # A tibble: 590 × 4 ##    Transect             geometry Effort Sample.Label ##  *    <dbl>          <POINT [°]>    [m] <chr>        ##  1        1 (-71.86887 41.29289)  1515. 2010-RI-1-1  ##  2        1  (-71.86764 41.2793)  1515. 2010-RI-1-2  ##  3        1  (-71.86642 41.2657)  1515. 2010-RI-1-3  ##  4        2 (-71.82799 41.29922)  1818. 2010-RI-2-1  ##  5        2  (-71.82654 41.2829)  1818. 2010-RI-2-2  ##  6        2 (-71.82508 41.26659)  1818. 2010-RI-2-3  ##  7        2 (-71.82363 41.25028)  1818. 2010-RI-2-4  ##  8        2 (-71.82218 41.23396)  1818. 2010-RI-2-5  ##  9        3 (-71.78729 41.30687)  1948. 2010-RI-3-1  ## 10        3  (-71.7858 41.28939)  1948. 2010-RI-3-2  ## # ℹ 580 more rows p <- ggplot() +   # geom_sf knows what to do with spatial data   geom_sf(data=coastline) +   geom_sf(data=transects) +   geom_sf(data=segs) +   # chop to be on a better scale   coord_sf(xlim=c(-72, -70.8), ylim=c(40.8, 41.5), expand=FALSE) +   # make the plot look simpler   theme_minimal() print(p) segs_df <- cbind(as.data.frame(st_drop_geometry(segs)),               st_coordinates(segs)) head(segs_df) ##   Transect       Effort Sample.Label         X        Y ## 1        1 1515.147 [m]  2010-RI-1-1 -71.86887 41.29289 ## 2        1 1515.151 [m]  2010-RI-1-2 -71.86764 41.27930 ## 3        1 1515.155 [m]  2010-RI-1-3 -71.86642 41.26570 ## 4        2 1818.179 [m]  2010-RI-2-1 -71.82799 41.29922 ## 5        2 1818.184 [m]  2010-RI-2-2 -71.82654 41.28290 ## 6        2 1818.190 [m]  2010-RI-2-3 -71.82508 41.26659"},{"path":"/articles/data_format/dsm-data-formatting.html","id":"linking-observations-and-segments","dir":"Articles > Data_format","previous_headings":"Table construction","what":"Linking observations and segments","title":"`dsm` data formatting example","text":"link together data detection function spatial data giving effort, use observation data.frame. really just cross-reference two tables, detection lives one segment. observation data.frame must (least) following columns: object : unique object identifier (corresponding identifiers detection function) Sample.Label : identifier segment observation occurred size : size observed group (e.g., 1 animals occurred individually) distance : distance observation observation data many rows detection function.","code":""},{"path":"/articles/data_format/dsm-data-formatting.html","id":"relating-observations-and-segments-in-practice","dir":"Articles > Data_format","previous_headings":"Table construction > Linking observations and segments","what":"Relating observations and segments in practice","title":"`dsm` data formatting example","text":"methods building observation table. ’ll illustrate one assigning detections segments based distance (.e., detections associated closest segment centroid). appropriate don’t see forwards far, ’s unlikely detections miss assigned. true, instance, aerial survey observers look windows located sides plane might inappropriate shipboard survey observers flying bridge can see way ahead ship. First loading detection data survey (use fit detection function, post-processing): can see columns latitude longitude (Lat Long). can make data.frame sf object telling sf columns contain spatial coordinates (sf lingo, “geometry”): can overlay previous map transects:  Going back segs object , can use st_join function, combined st_nearest_feature function control tables linked. , need project data avoid issues. Now obs acquired additional columns segs, including Sample.Label (want) Effort (don’t). check worked okay, can plot obs segs_lines (line version segments saved earlier) colour coding Sample.Label. randomized colour order easier tell observations misallocated.  segs can remove unnecessary columns geometry get required columns : (Note since binned data, just keep Bin column need process later.) different way approach timestamps waypoints GPS, related segments. One look whether observation made start end times segment.","code":"obs <- read.csv(\"data/loons.csv\") head(obs) ##         Date     Time Bin      Lat      Long Observer object size ## 1 2011-04-19 18991230   B 40.85296 -71.45511       JV     46    1 ## 2 2011-02-17 18991230   A 40.87022 -71.54842       JV    106    1 ## 3 2011-05-02 18991230   A 40.87595 -71.30304       KW    121    1 ## 4 2011-12-04 18991230   C 40.91753 -71.38273       KW    286    1 ## 5 2011-02-23 18991230   A 40.94153 -71.38517       KW    446    1 ## 6 2011-02-07 18991230   A 40.94225 -71.46438       KW    457    1 obs <- st_as_sf(obs, coords=c(\"Long\", \"Lat\")) # set the coordinate system st_crs(obs) <- 4326 obs ## Simple feature collection with 941 features and 6 fields ## Geometry type: POINT ## Dimension:     XY ## Bounding box:  xmin: -71.86962 ymin: 40.85296 xmax: -70.89175 ymax: 41.46472 ## Geodetic CRS:  WGS 84 ## First 10 features: ##          Date     Time Bin Observer object size                   geometry ## 1  2011-04-19 18991230   B       JV     46    1 POINT (-71.45511 40.85296) ## 2  2011-02-17 18991230   A       JV    106    1 POINT (-71.54842 40.87022) ## 3  2011-05-02 18991230   A       KW    121    1 POINT (-71.30304 40.87595) ## 4  2011-12-04 18991230   C       KW    286    1 POINT (-71.38273 40.91753) ## 5  2011-02-23 18991230   A       KW    446    1 POINT (-71.38517 40.94153) ## 6  2011-02-07 18991230   A       KW    457    1 POINT (-71.46438 40.94225) ## 7  2011-04-19 18991230   A       JV    500    2 POINT (-71.59495 40.94761) ## 8  2011-05-02 18991230   A       KW    506    1   POINT (-71.552 40.94795) ## 9  2011-02-23 18991230   B       JV    814    1 POINT (-71.51172 40.97912) ## 10 2011-04-19 18991230   A       KW    911    1 POINT (-71.59762 40.98571) p <- ggplot() +   # geom_sf knows what to do with spatial data   geom_sf(data=coastline) +   geom_sf(data=transects) +   geom_sf(data=obs, size=0.5) +   # chop to be on a better scale   coord_sf(xlim=c(-72, -70.8), ylim=c(40.8, 41.5), expand=FALSE) +   # make the plot look simpler   theme_minimal() print(p) # project segs segs <- st_transform(segs, 6348) obs <- st_transform(obs, 6348)  # do the join obs <- st_join(obs, segs, join=st_nearest_feature)   # project back to lat/long segs <- st_transform(segs, 4326) obs <- st_transform(obs, 4326)  # how does that look? obs ## Simple feature collection with 941 features and 9 fields ## Geometry type: POINT ## Dimension:     XY ## Bounding box:  xmin: -71.86962 ymin: 40.85296 xmax: -70.89175 ymax: 41.46472 ## Geodetic CRS:  WGS 84 ## First 10 features: ##          Date     Time Bin Observer object size Transect       Effort ## 1  2011-04-19 18991230   B       JV     46    1        8 1969.873 [m] ## 2  2011-02-17 18991230   A       JV    106    1       26 1894.100 [m] ## 3  2011-05-02 18991230   A       KW    121    1       12 1988.809 [m] ## 4  2011-12-04 18991230   C       KW    286    1       10 1979.630 [m] ## 5  2011-02-23 18991230   A       KW    446    1       10 1979.624 [m] ## 6  2011-02-07 18991230   A       KW    457    1        8 1969.839 [m] ## 7  2011-04-19 18991230   A       JV    500    2       24 1923.218 [m] ## 8  2011-05-02 18991230   A       KW    506    1       26 1894.075 [m] ## 9  2011-02-23 18991230   B       JV    814    1        7 2000.139 [m] ## 10 2011-04-19 18991230   A       KW    911    1       24 1923.199 [m] ##     Sample.Label                   geometry ## 1   2010-RI-8-29 POINT (-71.45511 40.85296) ## 2  2010-RI-26-16 POINT (-71.54842 40.87022) ## 3  2010-RI-12-31 POINT (-71.30304 40.87595) ## 4  2010-RI-10-27 POINT (-71.38273 40.91753) ## 5  2010-RI-10-26 POINT (-71.38517 40.94153) ## 6   2010-RI-8-24 POINT (-71.46438 40.94225) ## 7  2010-RI-24-12 POINT (-71.59495 40.94761) ## 8  2010-RI-26-12   POINT (-71.552 40.94795) ## 9   2010-RI-7-22 POINT (-71.51172 40.97912) ## 10  2010-RI-24-9 POINT (-71.59762 40.98571) # make a random colour palette to avoid similar colours being near each other pal <- rainbow(nrow(segs), s=.6, v=.9)[sample(1:nrow(segs),nrow(segs))] p <- ggplot() +   # geom_sf knows what to do with spatial data   geom_sf(data=coastline) +   geom_sf(data=segs_lines, aes(colour=Sample.Label), pch=21) +   geom_sf(data=obs, size=0.5, aes(colour=Sample.Label)) +   # chop to be on a better scale   coord_sf(xlim=c(-72, -70.8), ylim=c(40.8, 41.5), expand=FALSE) +   scale_colour_manual(values=pal) +   # make the plot look simpler   theme_minimal() +   theme(legend.position = \"none\") print(p) # get rid of \"spatialness\" obs <- st_drop_geometry(obs) # select the columns we need obs <- obs[, c(\"object\", \"Sample.Label\", \"size\", \"Bin\")] head(obs) ##   object  Sample.Label size Bin ## 1     46  2010-RI-8-29    1   B ## 2    106 2010-RI-26-16    1   A ## 3    121 2010-RI-12-31    1   A ## 4    286 2010-RI-10-27    1   C ## 5    446 2010-RI-10-26    1   A ## 6    457  2010-RI-8-24    1   A"},{"path":"/articles/data_format/dsm-data-formatting.html","id":"more-information","dir":"Articles > Data_format","previous_headings":"","what":"More information","title":"`dsm` data formatting example","text":"provided information segmenting wiki page, part US Navy-funded project DenMod. information summarized ?\"dsm-data\" dsm package. may also useful look data example dataset mexdolphins can loaded data(mexdolphins). vignette analysis data available . hard give general information segment lines, extent depends data originally formatted (going way back make model GPS unit used). information dealing spatial data R using sf package available R spatial website (see “Articles” drop header). Another source help distance sampling mailing list. sure search archives prior posting several threads segmenting previously might helpful.","code":""},{"path":"/articles/data_format/dsm-data-formatting.html","id":"acknowledgements","dir":"Articles > Data_format","previous_headings":"","what":"Acknowledgements","title":"`dsm` data formatting example","text":"Thanks Phil Bouchet providing helpful comments early version document Iúri Correia finding important bug.","code":""},{"path":[]},{"path":"/articles/lines_gomex/mexico-analysis.html","id":"introduction","dir":"Articles > Lines_gomex","previous_headings":"","what":"Introduction","title":"Example `dsm` analysis: pantropical dolphins in the Gulf of Mexico","text":"analysis based dataset observations pantropical dolphins Gulf Mexico (shipped Distance 6.0 later). convenience data bundled R-friendly format, although code necessary creating data Distance project files available github. OBIS-SEAMAP page data may found SEFSC GoMex Oceanic 1996 survey page. intention highlight features dsm package, rather perform full analysis data. reason, important steps fully explored. familiarity density surface modelling (Miller, Burt, Rexstad, & Thomas, 2013) (Hedley & Buckland, 2004) assumed.","code":""},{"path":"/articles/lines_gomex/mexico-analysis.html","id":"preamble","dir":"Articles > Lines_gomex","previous_headings":"","what":"Preamble","title":"Example `dsm` analysis: pantropical dolphins in the Gulf of Mexico","text":"start, load dsm package (dependencies) set options: order run vignette, ’ll need install R packages. can done via following call install.packages:","code":"library(dsm) library(ggplot2)  # plotting options gg.opts <- theme(panel.grid.major=element_blank(),                  panel.grid.minor=element_blank(),                  panel.background=element_blank()) install.packages(c(\"dsm\", \"Distance\", \"knitr\", \"distill\", \"ggplot2\", \"rgdal\",                    \"maptools\", \"plyr\", \"tweedie\"))"},{"path":"/articles/lines_gomex/mexico-analysis.html","id":"the-data","dir":"Articles > Lines_gomex","previous_headings":"","what":"The data","title":"Example `dsm` analysis: pantropical dolphins in the Gulf of Mexico","text":"data need included dsm package, two additional objects needed plotting required can downloaded put directory file. data can loaded R using following code: add objects survey.area pred.polys environment.","code":"load(\"mexdolphins-extra.rda\")"},{"path":"/articles/lines_gomex/mexico-analysis.html","id":"observation-and-segment-data","dir":"Articles > Lines_gomex","previous_headings":"The data","what":"Observation and segment data","title":"Example `dsm` analysis: pantropical dolphins in the Gulf of Mexico","text":"data analysis nicely pre-formatted shipped dsm. Loading data, can see four data.frames, first lines shown: segdata holds segment data: transects already “chopped” segments. distdata holds distance sampling data used fit detection function. obsdata links distance data segments. preddata holds prediction grid (includes necessary covariates). Typically (.e. datasets) necessary divide transects segments, allocate observations correct segments using GIS similar package1, starting analysis using dsm.","code":"data(mexdolphins) head(segdata) ##   longitude latitude        x        y Effort Transect.Label Sample.Label depth ## 1 -86.92712 29.94378 836105.9 -1011416  13800       19960417   19960417-1 135.0 ## 2 -86.83176 29.84030 846012.9 -1021407  14000       19960417   19960417-2 147.7 ## 3 -86.74445 29.75279 855022.6 -1029785  14000       19960417   19960417-3 152.1 ## 4 -86.65230 29.65522 864610.3 -1039168  13900       19960417   19960417-4 163.8 ## 5 -86.56648 29.56088 873598.1 -1048266  13800       19960417   19960417-5 179.7 ## 6 -86.49290 29.49000 881203.7 -1055004  13800       19960417   19960417-6 188.5 head(distdata) ##     object size  distance Effort detected beaufort latitude longitude ## 45      45   21 3296.6363  36300        1        4 27.72872 -86.00159 ## 61      61  150  929.1937  17800        1        4 25.99896 -87.62712 ## 63      63  125 6051.0009  21000        1        2 26.00693 -87.94881 ## 85      85   75 5499.6971  21800        1        1 27.50344 -90.44891 ## 114    114   50 7258.9837  13400        1        3 27.40568 -94.99483 ## 120    120   45 1454.7962  20900        1        5 26.01765 -95.97449 ##              x        y ## 45  948000.065 -1236192 ## 61  812161.653 -1436899 ## 63  780969.520 -1438985 ## 85  528656.807 -1297833 ## 114  95910.149 -1324562 ## 120   2477.665 -1473909 head(obsdata) ##     object Sample.Label size  distance Effort ## 45      45   19960421-9   21 3296.6363  36300 ## 61      61   19960423-7  150  929.1937  17800 ## 63      63   19960423-9  125 6051.0009  21000 ## 85      85   19960427-1   75 5499.6971  21800 ## 114    114   19960430-8   50 7258.9837  13400 ## 120    120   19960501-5   45 1454.7962  20900 head(preddata) ##   latitude longitude        x          y depth      area ## 1 30.08333 -87.58333 774402.9 -1002759.1    35 271236913 ## 2 30.08333 -87.41667 789688.6 -1001264.5    30 271236913 ## 3 30.08333 -87.25000 804971.3  -999740.6    27 271236913 ## 4 30.08333 -87.08333 820251.1  -998187.5    22 271236913 ## 5 30.08333 -86.91667 835528.0  -996605.2    46 271236913 ## 6 29.91667 -87.75000 760783.1 -1021810.3    14 271236913"},{"path":"/articles/lines_gomex/mexico-analysis.html","id":"shapefiles-and-converting-units","dir":"Articles > Lines_gomex","previous_headings":"The data","what":"Shapefiles and converting units","title":"Example `dsm` analysis: pantropical dolphins in the Gulf of Mexico","text":"Often data spatial analysis comes many different sources. important ensure measurements used analysis compatible units, otherwise resulting estimates incorrect hard interpret. measurements SI units outset removes need conversion later, making life much easier. data already appropriate units (Northings Eastings: kilometres centroid, projected using North American Lambert Conformal Conic projection). extensive literature particular projections latitude longitude appropriate highly recommend reader review particular study area; (Bivand, Pebesma, & Gómez-Rubio, 2008) good starting point. data frames already measurements appropriately converted. convention directions named x y. Using latitude longitude performing spatial smoothing can problematic certain smoother bases used. particular bivariate isotropic bases used non-isotropic nature latitude longitude inconsistent (moving one degree one direction moving one degree ). give example projecting polygon defines survey area (simply read R using readShapeSpatial shapefile produced GIS). Next bit code works study.area outline, massaging use soap film smoother. using soap film smoothers, code extraneous. code generates plot, shows survey area transect lines overlaid (using data segdata).  Also note since projected prediction grid, “squares” look quite like squares. plotting use polygons saved, polygons (stored pred.polys) read shapefile created GIS, object class SpatialPolygons sp package. needs project proper plotting using functions sf package. predsf <- st_as_sf(pred.polys)  Tips plotting polygons available ggplot2 pkg_down.","code":"library(sf) library(plyr)  # tell R that the survey.area object is currently in lat/long sp::proj4string(survey.area) <- sp::CRS(\"+proj=longlat +datum=WGS84\")  predsf <- st_as_sf(pred.polys)  area.sf <- st_as_sf(survey.area) st_crs(area.sf) <- \"WGS84\" area.sf.proj <- st_transform(area.sf, crs = st_crs(predsf))  # Convert preddata to a spatial object preddata_sf <- st_as_sf(preddata, coords=c(\"x\", \"y\")) st_crs(preddata_sf) <- st_crs(area.sf.proj) # Perform the intersection preddata_sf <- st_intersection(preddata_sf, area.sf.proj) ## Warning: attribute variables are assumed to be spatially constant throughout ## all geometries coords_preddata <- data.frame(st_coordinates(preddata_sf))  preddata_sf$x <- coords_preddata$X preddata_sf$y <- coords_preddata$Y # proj 4 string # using http://spatialreference.org/ref/esri/north-america-lambert-conformal-conic/ lcc_proj4 <- sp::CRS(\"+proj=lcc +lat_1=20 +lat_2=60 +lat_0=40 +lon_0=-96 +x_0=0 +y_0=0 +ellps=GRS80 +datum=NAD83 +units=m +no_defs \")  # project using LCC survey.area <- sp::spTransform(survey.area, CRSobj=lcc_proj4)  # simplify the object survey.area <- data.frame(survey.area@polygons[[1]]@Polygons[[1]]@coords) names(survey.area) <- c(\"x\", \"y\") segdata_sf <- st_as_sf(segdata, coords = c(\"x\",\"y\")) st_crs(segdata_sf) <- st_crs(area.sf.proj) # study area outline and segment centres plot_segments <- ggplot() +   geom_sf(data = area.sf.proj, fill=\"lightblue\", color = \"blue\", linewidth=.1) +   geom_sf(data=segdata_sf, fill=NA, color=\"black\", linewidth=.3) +   labs(title=\"1996 SE Fisheries Science Center Gulf of Mexico cruise\",        subtitle = \"Points are segment centres\") +   scale_fill_viridis_c(option = \"magma\", guide = \"none\") plot_segments predsf <- st_as_sf(pred.polys) # plot as projected plot(st_geometry(predsf), axes=TRUE)"},{"path":[]},{"path":"/articles/lines_gomex/mexico-analysis.html","id":"distance-data","dir":"Articles > Lines_gomex","previous_headings":"Exploratory data analysis","what":"Distance data","title":"Example `dsm` analysis: pantropical dolphins in the Gulf of Mexico","text":"top panels EDA plots show histograms observed distances cluster size, bottom panels show relationship observed distance observed cluster size, relationship observed distance Beaufort sea state. plots show relationship cluster size observed distance (fewer smaller clusters seem seen larger distances). following code generates EDA plots:  Top row, left right: histograms distance cluster size; bottom row: plot distance cluster size plot distances Beaufort sea state.","code":"par(mfrow=c(2,2))  # histograms hist(distdata$distance,main=\"\",xlab=\"Distance (m)\") hist(distdata$size,main=\"\",xlab=\"Cluster size\")  # plots of distance vs. cluster size plot(distdata$distance, distdata$size, main=\"\", xlab=\"Distance (m)\",      ylab=\"Group size\", pch=19, cex=0.5, col=gray(0.7))  # lm fit l.dat <- data.frame(distance=seq(0,8000,len=1000)) lo <- lm(size~distance, data=distdata) lines(l.dat$distance, as.vector(predict(lo,l.dat)))  plot(distdata$distance,distdata$beaufort, main=\"\", xlab=\"Distance (m)\",      ylab=\"Beaufort sea state\", pch=19, cex=0.5, col=gray(0.7))"},{"path":"/articles/lines_gomex/mexico-analysis.html","id":"spatial-data","dir":"Articles > Lines_gomex","previous_headings":"Exploratory data analysis","what":"Spatial data","title":"Example `dsm` analysis: pantropical dolphins in the Gulf of Mexico","text":"Looking separately spatial data without thinking distances, can plot observed group sizes space (point size proportional group size observation). Circle size indicates size group observation. rather large areas observations, might cause variance estimates abundance rather large. also see depth data use depth later explanatory covariate spatial model.","code":"prediction_grid <- st_make_grid(area.sf.proj, cellsize = c(9000,9000)) prediction_grid_sf <- st_sf(geometry = prediction_grid) cropped_grid <- st_join(prediction_grid_sf, preddata_sf, join = st_nearest_feature) cropped_grid <- st_intersection(cropped_grid, area.sf.proj) ## Warning: attribute variables are assumed to be spatially constant throughout ## all geometries depth <- ggplot() +          geom_sf(data=cropped_grid, aes(fill=depth), color=NA) +          labs(title = \"Spotted dolphins, Gulf of Mexico\",               subtitle = \"Depth in meters, size of detected dolphin groups\") +          xlab(\"Longitude\") + ylab(\"Latitude\") +          geom_point(aes(x, y, size=size), data=distdata, colour=\"red\",alpha=I(0.5)) +          scale_fill_viridis_c(option = \"viridis\", direction = 1) depth"},{"path":"/articles/lines_gomex/mexico-analysis.html","id":"estimating-the-detection-function","dir":"Articles > Lines_gomex","previous_headings":"","what":"Estimating the detection function","title":"Example `dsm` analysis: pantropical dolphins in the Gulf of Mexico","text":"use ds function package Distance fit detection function. (Distance package intended make standard distance sampling R relatively straightforward. flexible complex alternative, see function ddf mrds library.) First, loading Distance library: can fit detection function hazard-rate key adjustment terms: Calling summary gives us information parameter estimates, probability detection, AIC, etc: following code generates plot fitted detection function (left) quantile-quantile plot (right):  quantile-quantile plot show relatively good goodness fit hazard-rate detection function.","code":"library(Distance) detfc.hr.null <- ds(distdata, max(distdata$distance), key=\"hr\", adjustment=NULL) ## Warning in ddf.ds(dsmodel = dsmodel, data = data, meta.data = meta.data, : ## Estimated hazard-rate scale parameter close to 0 (on log scale). Possible ## problem in data (e.g., spike near zero distance). ## Warning in ds(distdata, max(distdata$distance), key = \"hr\", adjustment = NULL): ## Estimated hazard-rate scale parameter close to 0 (on log scale). Possible ## problem in data (e.g., spike near zero distance). summary(detfc.hr.null) ##  ## Summary for distance analysis  ## Number of observations :  47  ## Distance range         :  0  -  7847.467  ##  ## Model       : Hazard-rate key function  ## AIC         :  841.2528  ## Optimisation:  mrds (nlminb)  ##  ## Detection function parameters ## Scale coefficient(s):   ##             estimate        se ## (Intercept)  7.98244 0.9533779 ##  ## Shape coefficient(s):   ##             estimate        se ## (Intercept)        0 0.7833406 ##  ##                       Estimate         SE        CV ## Average p            0.5912252  0.2224714 0.3762887 ## N in covered region 79.4959326 30.8184416 0.3876732 plot(detfc.hr.null, showpoints=FALSE, pl.den=0, lwd=2) gof_ds(detfc.hr.null) ##  ## Goodness of fit results for ddf object ##  ## Distance sampling Cramer-von Mises test (unweighted) ## Test statistic = 0.0972004 p-value = 0.598774"},{"path":"/articles/lines_gomex/mexico-analysis.html","id":"adding-covariates-to-the-detection-function","dir":"Articles > Lines_gomex","previous_headings":"Estimating the detection function","what":"Adding covariates to the detection function","title":"Example `dsm` analysis: pantropical dolphins in the Gulf of Mexico","text":"common include covariates detection function (-called Multiple Covariate Distance Sampling MCDS). dataset two covariates collected individual: Beaufort sea state size. brevity fit hazard-rate detection functions sea state included factor covariate follows: looking summary, detection function covariates give lower AIC model without covariates (843.71 vs. 841.25 hazard-rate model without covariates). Looking back bottom-right panel EDA plots, can see discernible pattern plot Beaufort vs distance. brevity, detection function model selection omitted . practise fit many different forms detection function (select model based goodness fit testing AIC).","code":"detfc.hr.beau<-ds(distdata, max(distdata$distance), formula=~as.factor(beaufort),                   key=\"hr\", adjustment=NULL) summary(detfc.hr.beau) ##  ## Summary for distance analysis  ## Number of observations :  47  ## Distance range         :  0  -  7847.467  ##  ## Model       : Hazard-rate key function  ## AIC         :  843.7117  ## Optimisation:  mrds (nlminb)  ##  ## Detection function parameters ## Scale coefficient(s):   ##                        estimate        se ## (Intercept)           7.6631807  1.077115 ## as.factor(beaufort)2  2.2796347 17.294287 ## as.factor(beaufort)3  0.2860623  1.019185 ## as.factor(beaufort)4  0.0717478  1.223465 ## as.factor(beaufort)5 -0.3639848  1.537672 ##  ## Shape coefficient(s):   ##              estimate        se ## (Intercept) 0.3004326 0.5179983 ##  ##                       Estimate         SE        CV ## Average p            0.5421265  0.1750696 0.3229313 ## N in covered region 86.6956354 29.4151901 0.3392926"},{"path":"/articles/lines_gomex/mexico-analysis.html","id":"fitting-a-dsm","dir":"Articles > Lines_gomex","previous_headings":"","what":"Fitting a DSM","title":"Example `dsm` analysis: pantropical dolphins in the Gulf of Mexico","text":"fitting dsm model, data must segmented; consists chopping transects attributing counts segments. mentioned , data already segmented.","code":""},{"path":"/articles/lines_gomex/mexico-analysis.html","id":"a-simple-model","dir":"Articles > Lines_gomex","previous_headings":"Fitting a DSM","what":"A simple model","title":"Example `dsm` analysis: pantropical dolphins in the Gulf of Mexico","text":"begin simple model. assume number individuals segment quasi-Poisson distributed smooth function spatial coordinates (note formula exactly one specify gam mgcv). setting group=TRUE, abundance clusters/groups rather individuals can estimated (though ignore ). Note set method=\"REML\" ensure smooth terms estimated reliably. Running model: can obtain summary fitted model: exact interpretation model summary results can found (S. N. Wood, 2017); can see various information smooth components fitted general model statistics. can use deviance explained compare models2. can also get rough idea smooth space looks like using vis.gam (white/yellow indicates high values, red low indicates low values):  type=\"response\" argument ensures plot scale abundance values relative (offsets set median values). means plot useful get idea general shape smooth interpreted directly.","code":"dsm.xy <- dsm(count~s(x,y), detfc.hr.null, segdata, obsdata, method=\"REML\") summary(dsm.xy) ##  ## Family: quasipoisson  ## Link function: log  ##  ## Formula: ## count ~ s(x, y) + offset(off.set) ##  ## Parametric coefficients: ##             Estimate Std. Error t value Pr(>|t|)     ## (Intercept)   -18.20       0.53  -34.34   <2e-16 *** ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Approximate significance of smooth terms: ##         edf Ref.df     F  p-value     ## s(x,y) 24.8  27.49 2.354 0.000733 *** ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## R-sq.(adj) =  0.121   Deviance explained = 43.4% ## -REML = 936.04  Scale est. = 94.367    n = 387 vis.gam(dsm.xy, plot.type=\"contour\", view=c(\"x\",\"y\"), asp=1, type=\"response\", contour.col=\"black\", n.grid=100)"},{"path":"/articles/lines_gomex/mexico-analysis.html","id":"adding-another-environmental-covariate-to-the-spatial-model","dir":"Articles > Lines_gomex","previous_headings":"Fitting a DSM","what":"Adding another environmental covariate to the spatial model","title":"Example `dsm` analysis: pantropical dolphins in the Gulf of Mexico","text":"data set also contains depth covariate (plotted ). can include model simply: see drop deviance explained, perhaps model useful first. discuss setting k parameter Model checking, . Setting select=TRUE (argument gam) impose extra shrinkage terms smooth model (allowing smooth terms removed model fitting; see ?gam information). particularly useful , include . However many environmental predictors model can good way (along looking \\(p\\)-values) perform term selection. Simply calling plot model object allows us look relationship depth linear predictor:  Omitting argument select call plot plot smooth terms, one time.","code":"dsm.xy.depth <- dsm(count~s(x,y,k=10) + s(depth,k=20), detfc.hr.null, segdata, obsdata, method=\"REML\") summary(dsm.xy.depth) ##  ## Family: quasipoisson  ## Link function: log  ##  ## Formula: ## count ~ s(x, y, k = 10) + s(depth, k = 20) + offset(off.set) ##  ## Parametric coefficients: ##             Estimate Std. Error t value Pr(>|t|)     ## (Intercept)  -18.740      1.236  -15.16   <2e-16 *** ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Approximate significance of smooth terms: ##            edf Ref.df     F p-value   ## s(x,y)   6.062  7.371 0.923  0.5038   ## s(depth) 9.443 11.466 1.585  0.0824 . ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## R-sq.(adj) =  0.0909   Deviance explained = 34.3% ## -REML = 939.52  Scale est. = 124.9     n = 387 plot(dsm.xy.depth, select=2)"},{"path":"/articles/lines_gomex/mexico-analysis.html","id":"spatial-models-when-there-are-covariates-in-the-detection-function","dir":"Articles > Lines_gomex","previous_headings":"Fitting a DSM","what":"Spatial models when there are covariates in the detection function","title":"Example `dsm` analysis: pantropical dolphins in the Gulf of Mexico","text":"code fit DSM covariates detection function similar models, . However since detection function observation-level covariates, must estimate abundance per segment using Horvitz-Thompson-like estimator modelling, change response abundance.est: can see, summary results rather similar: resulting spatial smooth (though resulting surface somewhat “amplified”):","code":"dsm.est.xy <- dsm(abundance.est~s(x,y), detfc.hr.beau, segdata, obsdata, method=\"REML\") summary(dsm.est.xy) ##  ## Family: quasipoisson  ## Link function: log  ##  ## Formula: ## abundance.est ~ s(x, y) + offset(off.set) ##  ## Parametric coefficients: ##             Estimate Std. Error t value Pr(>|t|)     ## (Intercept) -18.0234     0.4738  -38.04   <2e-16 *** ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Approximate significance of smooth terms: ##          edf Ref.df    F  p-value     ## s(x,y) 24.64  27.43 2.35 0.000289 *** ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## R-sq.(adj) =  0.129   Deviance explained = 42.2% ## -REML = 1043.6  Scale est. = 174.08    n = 387 vis.gam(dsm.est.xy, plot.type=\"contour\", view=c(\"x\",\"y\"), asp=1, type=\"response\", zlim=c(0, 300), contour.col=\"black\", n.grid=100)"},{"path":"/articles/lines_gomex/mexico-analysis.html","id":"other-response-distributions","dir":"Articles > Lines_gomex","previous_headings":"Fitting a DSM","what":"Other response distributions","title":"Example `dsm` analysis: pantropical dolphins in the Gulf of Mexico","text":"Often quasi-Poisson distribution doesn’t give adequate flexibility capture overdispersion response data (see Model checking Model selection ), illustrate two additional distributions can used count data. models section, ’ll move back count response, though estimated abundance also work.","code":""},{"path":"/articles/lines_gomex/mexico-analysis.html","id":"tweedie","dir":"Articles > Lines_gomex","previous_headings":"Fitting a DSM > Other response distributions","what":"Tweedie","title":"Example `dsm` analysis: pantropical dolphins in the Gulf of Mexico","text":"Response distributions quasi-Poisson can used, example Tweedie distribution. Tweedie distribution available dsm setting family=tw().","code":"dsm.xy.tweedie <- dsm(count~s(x,y), detfc.hr.null, segdata, obsdata, family=tw(), method=\"REML\") summary(dsm.xy.tweedie) ##  ## Family: Tweedie(p=1.347)  ## Link function: log  ##  ## Formula: ## count ~ s(x, y) + offset(off.set) ##  ## Parametric coefficients: ##             Estimate Std. Error t value Pr(>|t|)     ## (Intercept) -17.2640     0.2363  -73.07   <2e-16 *** ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Approximate significance of smooth terms: ##          edf Ref.df     F p-value   ## s(x,y) 12.82  17.13 1.628  0.0562 . ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## R-sq.(adj) =  0.0684   Deviance explained = 26.8% ## -REML = 351.49  Scale est. = 60.26     n = 387"},{"path":"/articles/lines_gomex/mexico-analysis.html","id":"negative-binomial","dir":"Articles > Lines_gomex","previous_headings":"Fitting a DSM > Other response distributions","what":"Negative binomial","title":"Example `dsm` analysis: pantropical dolphins in the Gulf of Mexico","text":"Though used , similarly, two options negative binomial distribution: negbin nb. former requires user specification single parameter theta range values parameter (specified vector), latter estimates value theta model fitting process (generally faster). latter recommended users.","code":""},{"path":"/articles/lines_gomex/mexico-analysis.html","id":"other-spatial-modelling-options","dir":"Articles > Lines_gomex","previous_headings":"Fitting a DSM","what":"Other spatial modelling options","title":"Example `dsm` analysis: pantropical dolphins in the Gulf of Mexico","text":"large literature spatial modelling using GAMs, much can harnessed DSM context. highlights.","code":""},{"path":"/articles/lines_gomex/mexico-analysis.html","id":"soap-film-smoothing","dir":"Articles > Lines_gomex","previous_headings":"Fitting a DSM > Other spatial modelling options","what":"Soap film smoothing","title":"Example `dsm` analysis: pantropical dolphins in the Gulf of Mexico","text":"account complex region (e.g., region includes peninsulae) can use soap film smoother (Simon N. Wood, Bravington, & Hedley, 2008). use soap film smoother spatial part model must create set knots smoother use. easily done using make.soapgrid() function dsm: second argument specifies number points (direction) grid used create knots (knots grid outside survey.area removed). saw exploratory analysis, transect lines outside survey area. cause soap film smoother fail, remove : Note soap_checker script available can useful ensuring boundary, data knots correct format use soap film smoother. can run model depth covariate along spatial (soap film) smooth. Note k argument now refers complexity boundary smooth soap film, complexity film controlled knots given xt argument.","code":"soap.knots <- make.soapgrid(survey.area,c(15,10)) x <- segdata$x; y<-segdata$y onoff <- inSide(x=x,y=y, bnd=as.list(survey.area)) rm(x,y) segdata.soap <- segdata[onoff,] dsm.xy.tweedie.soap<-dsm(count~s(x, y, bs=\"so\", k=15, xt=list(bnd=list(survey.area))) +             s(depth),           family=tw(), method=\"REML\",           detfc.hr.null, segdata.soap, obsdata, knots=soap.knots) summary(dsm.xy.tweedie.soap) ##  ## Family: Tweedie(p=1.356)  ## Link function: log  ##  ## Formula: ## count ~ s(x, y, bs = \"so\", k = 15, xt = list(bnd = list(survey.area))) +  ##     s(depth) + offset(off.set) ##  ## Parametric coefficients: ##             Estimate Std. Error t value Pr(>|t|)     ## (Intercept)  -18.017      0.405  -44.49   <2e-16 *** ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Approximate significance of smooth terms: ##            edf Ref.df     F  p-value     ## s(x,y)   3.050 72.000 0.064 0.114944     ## s(depth) 5.135  6.196 3.895 0.000793 *** ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## R-sq.(adj) =  0.0653   Deviance explained = 33.1% ## -REML = 339.26  Scale est. = 54.022    n = 365"},{"path":"/articles/lines_gomex/mexico-analysis.html","id":"model-checking","dir":"Articles > Lines_gomex","previous_headings":"","what":"Model checking","title":"Example `dsm` analysis: pantropical dolphins in the Gulf of Mexico","text":"Fitting models well good, ’d like confirm models reasonable; dsm provides functions model checking. can use gam.check generate diagnostic plots:  show deviation Q-Q plot. “line” points plot residuals vs. linear predictor plot corresponds zeros data. Note well plots, gam.check also produces information model fitting. particular interest us last lines tell us basis size. k parameter provided s (te) terms dsm controls complexity smooths model. setting k parameter specify largest complexity smooth term model; long high enough, can sure enough flexibility. output gam.check , can see “p-value” calculated size basis, can good guide whether basis size needs increased. ?choose.k manual page mgcv gives guidance technical details matter. can look model form Tweedie distribution specified response:  Q-Q plot now seems much better (closer \\(y=x\\) line). plots histogram residuals rather hard interpret due large number zeros data. guidance interpreting gam.check output can found (S. N. Wood, 2017).","code":"gam.check(dsm.xy) ##  ## Method: REML   Optimizer: outer newton ## full convergence after 6 iterations. ## Gradient range [-7.105973e-08,-9.826122e-09] ## (score 936.0363 & scale 94.3674). ## Hessian positive definite, eigenvalue range [5.800328,192.5304]. ## Model rank =  30 / 30  ##  ## Basis dimension (k) checking results. Low p-value (k-index<1) may ## indicate that k is too low, especially if edf is close to k'. ##  ##          k'  edf k-index p-value ## s(x,y) 29.0 24.8    1.01    0.99 gam.check(dsm.xy.tweedie) ##  ## Method: REML   Optimizer: outer newton ## full convergence after 8 iterations. ## Gradient range [-1.513175e-06,3.981813e-06] ## (score 351.486 & scale 60.26034). ## Hessian positive definite, eigenvalue range [0.6230615,103.5094]. ## Model rank =  30 / 30  ##  ## Basis dimension (k) checking results. Low p-value (k-index<1) may ## indicate that k is too low, especially if edf is close to k'. ##  ##          k'  edf k-index p-value ## s(x,y) 29.0 12.8    0.73    0.34"},{"path":"/articles/lines_gomex/mexico-analysis.html","id":"randomised-quantile-residuals","dir":"Articles > Lines_gomex","previous_headings":"Model checking","what":"Randomised quantile residuals","title":"Example `dsm` analysis: pantropical dolphins in the Gulf of Mexico","text":"top right panel gam.check plots residuals vs. linear predictor plot includes odd line predictions. artifact link function, showing exact zeros data. can misleading distracting, making difficult see whether residuals show heteroskedasticity. Randomised quantile residuals (Dunn & Smyth, 1996) avoid issue transforming residuals exactly normally distributed. makes residuals vs. linear predictor plot much easier interpret therefore doesn’t include artifacts generated link function. plots can produced using rqgam.check dsm:  can see issue heteroskedasticity (increase spread residuals vs. linear predictor plot increasing values linear predictor). One can also plot residuals covariate values check pattern residuals. Note general, plots “Resids vs. linear pred.” interpreted caution output rqgam.check residuals generated normal construction (example Q-Q plot histogram residuals always look fine).","code":"rqgam_check(dsm.xy.tweedie)"},{"path":"/articles/lines_gomex/mexico-analysis.html","id":"model-selection","dir":"Articles > Lines_gomex","previous_headings":"","what":"Model selection","title":"Example `dsm` analysis: pantropical dolphins in the Gulf of Mexico","text":"Assuming models “passed” checks gam.check, rqgam.check sufficiently flexible, may left choice model “best”. several methods choosing best model – AIC, REML/GCV scores, deviance explained, full cross-validation test data . Though document intend full analysis pantropical dolphin data, can create results table compare various models fitted far terms abundance estimates associated uncertainties. can use resulting data.frame build table results using kable function:","code":"# make a data.frame to print out mod_results <- data.frame(\"Model name\" = c(\"`dsm.xy`\", \"`dsm.xy.depth`\", \"`dsm.xy.tweedie`\", \"`dsm.xy.tweedie.soap`\",                                            \"`dsm.est.xy`\"),                           \"Description\" = c(\"Bivariate smooth of location, quasipoisson\",                                             \"Bivariate smooth of location, smooth of depth, quasipoisson\",                                             \"Bivariate smooth of location, smooth of depth, Tweedie\",                                             \"Soap film smooth of location, smooth of depth, Tweedie\",                                             \"Bivariate smooth of location, smooth of depth, Tweedie, Beaufort covariate in detection function\"),                           \"Deviance explained\" = c(unlist(lapply(list(dsm.xy,                                                                       dsm.xy.depth,                                                                       dsm.xy.tweedie,                                                                       dsm.xy.tweedie.soap),                  function(x){paste0(round(summary(x)$dev.expl*100,2),\"%\")})),NA)) kable(mod_results, col.names=c(\"Model name\", \"Description\", \"Deviance explained\"))"},{"path":"/articles/lines_gomex/mexico-analysis.html","id":"abundance-estimation","dir":"Articles > Lines_gomex","previous_headings":"","what":"Abundance estimation","title":"Example `dsm` analysis: pantropical dolphins in the Gulf of Mexico","text":"model checked selected, can make predictions grid calculate abundance. offset stored area column3. Given predicted abundance estimates cell prediction grid, connected prediction grid object mapping:  can calculate abundance survey area simply summing predictions: can compare plot predictions dsm.xy.depth:  can see inclusion depth model noticeable effect distribution (note difference legend scale two plots). can also look total abundance: see much change abundance, terms abundance alone isn’t much two models. Next ’ll go look variance next can see bigger differences models.","code":"dsm.xy.pred <- predict(dsm.xy, preddata, preddata$area) prediction_grid <- st_make_grid(area.sf.proj, cellsize = c(9000,9000)) prediction_grid_sf <- st_sf(geometry = prediction_grid)  preddata_sf$Prediction_xy <- dsm.xy.pred  cropped_grid <- st_join(prediction_grid_sf, preddata_sf, join = st_nearest_feature) cropped_grid <- st_intersection(cropped_grid, area.sf.proj) ## Warning: attribute variables are assumed to be spatially constant throughout ## all geometries pred <- ggplot() +   geom_sf(data = cropped_grid, aes(fill = Prediction_xy), color = NA) +   geom_sf(data=segdata_sf, fill=NA, color=\"white\", linewidth=.001) +   labs(title=\"Spotted dolphins, Gulf of Mexico, abundance estimates\",        subtitle = \"Bivariate smooth of location, quasipoisson\") +   scale_fill_viridis_c(option = \"viridis\", direction = 1) pred sum(dsm.xy.pred) ## [1] 28462.22 dsm.xy.depth.pred <- predict(dsm.xy.depth, preddata, preddata$area)  preddata_sf$Prediction_xy_depth <- dsm.xy.depth.pred  cropped_grid <- st_join(prediction_grid_sf, preddata_sf, join = st_nearest_feature) cropped_grid <- st_intersection(cropped_grid, area.sf.proj) ## Warning: attribute variables are assumed to be spatially constant throughout ## all geometries pred <- ggplot() +   geom_sf(data = cropped_grid, aes(fill = Prediction_xy_depth), color = NA) +   geom_sf(data=segdata_sf, fill=NA, color=\"white\", linewidth=.001) +   labs(title=\"Spotted dolphins, Gulf of Mexico, abundance estimates\",        subtitle = \"Bivariate smooth of location, smooth of depth, quasipoisson\") +   scale_fill_viridis_c(option = \"viridis\", direction = 1) pred sum(dsm.xy.depth.pred) ## [1] 27084.54"},{"path":"/articles/lines_gomex/mexico-analysis.html","id":"variance-estimation","dir":"Articles > Lines_gomex","previous_headings":"","what":"Variance estimation","title":"Example `dsm` analysis: pantropical dolphins in the Gulf of Mexico","text":"Obviously point estimates abundance important, also calculate uncertainty around abundance estimates. Fortunately dsm provides functions perform calculations display resulting uncertainty estimates. two approaches estimating uncertainty abundance estimate dsm. dsm_var_gam assumes spatial model detection function parts model independent . case squared coefficients variation model component added. dsm_var_prop takes account fact detection probability may correlated spatial part model. uses methods described (Bravington, Miller, & Hedley, 2021). dsm_var_prop can applied covariate detection function varies level segments, recorded segment (example Beaufort). don’t situation , opt dsm_var_gam. methods estimate variance abundance element list provided pred.data. case wish obtain abundance prediction cells, use split chop data set list elements give dsm_var_gam (dsm_var_prop). Calling summary give information uncertainty estimation: can also make plot CVs (transect lines observations overlaid) using following code.  Note increase CV away transect lines. can revisit model included depth location smooths observe coefficient variation model larger model location smooth.","code":"preddata.var <- split(preddata, 1:nrow(preddata)) dsm.xy.var <- dsm_var_gam(dsm.xy, pred.data=preddata.var,                           off.set=preddata$area) summary(dsm.xy.var) ## Summary of uncertainty in a density surface model calculated ##  analytically for GAM, with delta method ##  ## Approximate asymptotic confidence interval: ##     2.5%     Mean    97.5%  ## 13133.77 28462.22 61680.55  ## (Using log-Normal approximation) ##  ## Point estimate                 : 28462.22  ## CV of detection function       : 0.3762887  ## CV from GAM                    : 0.164  ## Total standard error           : 11682.74  ## Total coefficient of variation : 0.4105 preddata_sf$CV <- sqrt(dsm.xy.var$pred.var)/preddata_sf$Prediction_xy  cropped_grid <- st_join(prediction_grid_sf, preddata_sf, join = st_nearest_feature) cropped_grid <- st_intersection(cropped_grid, area.sf.proj) ## Warning: attribute variables are assumed to be spatially constant throughout ## all geometries CV <- ggplot() +   geom_sf(data = cropped_grid, aes(fill = CV), color = NA) +   geom_sf(data=segdata_sf, fill=NA, color=\"white\", linewidth=.001) +   labs(title=\"Spotted dolphins, Gulf of Mexico, uncertainty (CV)\",        subtitle = \"Bivariate smooth of location, quasipoisson\") +   scale_fill_viridis_c(option = \"viridis\", direction = 1) CV dsm.xy.depth.var <- dsm_var_gam(dsm.xy.depth, pred.data=preddata.var,                                 off.set=preddata$area) summary(dsm.xy.depth.var) ## Summary of uncertainty in a density surface model calculated ##  analytically for GAM, with delta method ##  ## Approximate asymptotic confidence interval: ##     2.5%     Mean    97.5%  ## 12407.79 27084.54 59121.90  ## (Using log-Normal approximation) ##  ## Point estimate                 : 27084.54  ## CV of detection function       : 0.3762887  ## CV from GAM                    : 0.1741  ## Total standard error           : 11229.87  ## Total coefficient of variation : 0.4146"},{"path":"/articles/lines_gomex/mexico-analysis.html","id":"conclusions","dir":"Articles > Lines_gomex","previous_headings":"","what":"Conclusions","title":"Example `dsm` analysis: pantropical dolphins in the Gulf of Mexico","text":"document outlined analysis spatially-explicit distance sampling data using dsm package. Note many possible models can fitted using dsm aim show just options. Results models can rather different, care must taken performing model selection, discrimination criticism.","code":""},{"path":"/articles/lines_gomex/mexico-analysis.html","id":"software","dir":"Articles > Lines_gomex","previous_headings":"","what":"Software","title":"Example `dsm` analysis: pantropical dolphins in the Gulf of Mexico","text":"Distance available http://github.com/DistanceDevelopment/Distance well CRAN. dsm available http://github.com/DistanceDevelopment/dsm, well CRAN.","code":""},{"path":[]},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Laura Marshall. Maintainer. David L. Miller. Author. Eric Rexstad. Contributor. Louise Burt. Contributor. Mark V. Bravington. Contributor. Sharon Hedley. Contributor. Megan Ferguson. Contributor. Natalie Kelly. Contributor.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Miller DL (2025). dsm: Density Surface Modelling Distance Sampling Data. R package version 2.3.4, https://github.com/DistanceDevelopment/dsm.","code":"@Manual{,   title = {dsm: Density Surface Modelling of Distance Sampling Data},   author = {David L. Miller},   year = {2025},   note = {R package version 2.3.4},   url = {https://github.com/DistanceDevelopment/dsm}, }"},{"path":[]},{"path":"/index.html","id":"what-is-dsm","dir":"","previous_headings":"","what":"Density Surface Modelling of Distance Sampling Data","title":"Density Surface Modelling of Distance Sampling Data","text":"dsm provides Generalized Additive Model (GAM)-based approach calculate spatially-explicit estimates animal abundance distance sampling (also presence/absence strip transect) data. Several utility functions provided model checking, plotting variance estimation. Open Access paper describing methods: Miller, DL, ML Burt, EA Rexstad L Thomas (2013). Spatial models distance sampling data: recent developments future directions. Methods Ecology Evolution. https://doi.org/10.1111/2041-210X.12105","code":""},{"path":"/index.html","id":"using-dsm","dir":"","previous_headings":"","what":"Using dsm","title":"Density Surface Modelling of Distance Sampling Data","text":"Examples use dsm see https://distancesampling.org/dsm/articles/data_format/dsm-data-formatting.html https://distancesampling.org/dsm/articles/lines_gomex/mexico-analysis.html","code":""},{"path":"/reference/block.info.per.su.html","id":null,"dir":"Reference","previous_headings":"","what":"Find the block information — block.info.per.su","title":"Find the block information — block.info.per.su","text":"Takes transect data works many blocks given size (segment terms) fit .","code":""},{"path":"/reference/block.info.per.su.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find the block information — block.info.per.su","text":"","code":"block.info.per.su(block.size, data, name.su)"},{"path":"/reference/block.info.per.su.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find the block information — block.info.per.su","text":"block.size number segments per block data data used build model name.su names sampling units (.e., transects)","code":""},{"path":"/reference/block.info.per.su.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find the block information — block.info.per.su","text":"data.frame following columns name        sample unit name (e.g. transect label) num.seg     number segments transect num.block   number blocks available start.block block number first block end.block   block number last block num.req     number blocks needed unit","code":""},{"path":"/reference/check.cols.html","id":null,"dir":"Reference","previous_headings":"","what":"Check column names exist — check.cols","title":"Check column names exist — check.cols","text":"Internal function check supplied data.frames correct columns checks sample labels unique.","code":""},{"path":"/reference/check.cols.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check column names exist — check.cols","text":"","code":"check.cols(ddf.obj, segment.data, observation.data, segment.area)"},{"path":"/reference/check.cols.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check column names exist — check.cols","text":"ddf.obj ddf object mrds segment.data segment data defined dsm observation.data observation data defined dsm segment.area area segments","code":""},{"path":"/reference/check.cols.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check column names exist — check.cols","text":"nothing, throws error something went wrong","code":""},{"path":"/reference/check.cols.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Check column names exist — check.cols","text":"David Lawrence Miller","code":""},{"path":"/reference/dsm-data.html","id":null,"dir":"Reference","previous_headings":"","what":"Data format for DSM — dsm-data","title":"Data format for DSM — dsm-data","text":"Two data.frames must provided dsm. referred observation.data segment.data.","code":""},{"path":"/reference/dsm-data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Data format for DSM — dsm-data","text":"segment.data table sample identifiers define segments, corresponding effort (line length) expended environmental covariates used model abundance/density. observation.data provides link table observations used detection function samples (segments), can aggregate observations segments (.e., observation.data \"look-table\" observations segments). observation.data - observation data.frame must (least) following columns: object unique object identifier Sample.Label identifier segment observation occurred size size observed group (e.g., 1 animals occurred individually) distance distance observation One can often also use observation.data fit detection function (additional columns detection function covariates allowed table). segment.data: segment data.frame must (least) following columns: Effort effort (terms length segment) Sample.Label identifier segment (unique!) ??? environmental covariates, example location (projected latitude longitude), relevant covariates (sea surface temperature, foliage type, altitude, bathymetry etc).","code":""},{"path":"/reference/dsm-data.html","id":"multiple-detection-functions","dir":"Reference","previous_headings":"","what":"Multiple detection functions","title":"Data format for DSM — dsm-data","text":"multiple detection functions used, column named ddfobj must included observation.data segment.data. lets model know detection function observation . numeric ordered ddf.obj argument dsm, e.g., ddf.obj=list(ship_ddf, aerial_ddf) means ship detections ddfobj=1 aerial detections ddfobj=2 observation data.","code":""},{"path":"/reference/dsm-data.html","id":"mark-recapture-distance-sampling-models","dir":"Reference","previous_headings":"","what":"Mark-recapture distance sampling models","title":"Data format for DSM — dsm-data","text":"using mrds models include mark-recapture components (currently independent observer trial modes supported) format observation data needs checked ensure observations duplicated. observer column also required observation.data. Independent observer mode unique observations (unique object IDs) required. Trial mode observations made observer 1 required.","code":""},{"path":"/reference/dsm-package.html","id":null,"dir":"Reference","previous_headings":"","what":"Density surface modelling — dsm-package","title":"Density surface modelling — dsm-package","text":"dsm implements spatial models distance sampling data. Models detectability can fitted using packages mrds Distance. dsm fits generalized additive models spatially-referenced data. See Miller et al (2013) introduction.","code":""},{"path":"/reference/dsm-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Density surface modelling — dsm-package","text":"information distance sampling methods example code (including example analyses) available https://distancesampling.org/software/Rpackages.html. help distance sampling package, Google Group https://groups.google.com/forum/#!forum/distance-sampling.","code":""},{"path":"/reference/dsm-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Density surface modelling — dsm-package","text":"Hedley, S. S. T. Buckland. 2004. Spatial models line transect sampling. JABES 9:181-199. Miller, D. L., Burt, M. L., Rexstad, E. ., Thomas, L. (2013), Spatial models distance sampling data: recent developments future directions. Methods Ecology Evolution, 4: 1001-1010. doi: 10.1111/2041-210X.12105 (Open Access) Wood, S.N. 2006. Generalized Additive Models: Introduction R. CRC/Chapman & Hall.","code":""},{"path":"/reference/dsm.cor.html","id":null,"dir":"Reference","previous_headings":"","what":"Check for autocorrelation in residuals — dsm.cor","title":"Check for autocorrelation in residuals — dsm.cor","text":"function deprecated, use dsm_cor.","code":""},{"path":"/reference/dsm.cor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check for autocorrelation in residuals — dsm.cor","text":"","code":"dsm.cor(   dsm.obj,   Transect.Label = \"Transect.Label\",   Segment.Label = \"Segment.Label\",   max.lag = 10,   resid.type = \"scaled.pearson\",   fun = cor,   ylim = c(0, 1),   subset = \"all\",   ... )"},{"path":"/reference/dsm.cor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check for autocorrelation in residuals — dsm.cor","text":"dsm.obj fitted dsm object. Transect.Label label transect (default: Transect.Label). Using different labels can useful transects split geographical features transects surveyed multiple times. Segment.Label label segments (default: Segment.Label).result calling order must make sense. max.lag maximum lag calculate . resid.type type residuals used, see residuals.gam. Defaults \"scaled.pearson\" GAM case \"normalized\" GAMM case (equivalent). fun function use, default cor, must take two column vectors arguments. ylim user defined limits y direction. subset subset data correlation function calculated ? ... options pass plot.","code":""},{"path":"/reference/dsm.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit a density surface model to segment-specific estimates of abundance or density. — dsm","title":"Fit a density surface model to segment-specific estimates of abundance or density. — dsm","text":"Fits density surface model (DSM) detection adjusted counts spatially-referenced distance sampling analysis. dsm takes observations animals, allocates segments line (strip transects) optionally adjusts counts based detectability using supplied detection function model. generalized additive model, generalized mixed model generalized linear model used model adjusted counts based formula involving environmental covariates.","code":""},{"path":"/reference/dsm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit a density surface model to segment-specific estimates of abundance or density. — dsm","text":"","code":"dsm(   formula,   ddf.obj,   segment.data,   observation.data,   engine = \"gam\",   convert.units = 1,   family = quasipoisson(link = \"log\"),   group = FALSE,   control = list(keepData = TRUE),   availability = 1,   segment.area = NULL,   weights = NULL,   method = \"REML\",   ... )"},{"path":"/reference/dsm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit a density surface model to segment-specific estimates of abundance or density. — dsm","text":"formula formula surface. valid formula. See \"Details\", , define response. ddf.obj result call ddf ds. multiple detection functions required list can provided. strip/circle transects assumed objects observed, see dummy_ddf. Mark-recapture distance sampling (mrds) models type io (independent observers) trial allowed. segment.data segment data, see dsm-data. observation.data observation data, see dsm-data. engine fitting engine used DSM (\"glm\"/\"gam\"/\"gamm\"/\"bam\"). convert.units conversion factor multiply area segments . See 'Units' . family response distribution (popular choices include quasipoisson, Tweedie/tw negbin/nb). Defaults quasipoisson. group TRUE abundance groups calculated rather abundance individuals. Setting option TRUE equivalent setting size group 1. control usual control argument gam; keepData must TRUE variance estimation work (though option set GLMs GAMMs). availability estimate availability bias. count models used multiply effective strip width (must vector length 1 length number rows segment.data); estimated abundance/estimated density models used scale response (must vector length 1 length number rows observation.data). Uncertainty availability handled present. segment.area NULL (default) segment areas calculated multiplying Effort column segment.data (right minus left) truncation distance ddf.obj strip.width. Alternatively vector segment areas can provided (must length number rows segment.data) character string giving name column segment.data contains areas. segment.area specified takes precedent. weights weights observation used model fitting. default, weights=NULL, weights observation area (see Details). Setting scalar value (e.g., weights=1) observations equally weighted. method smoothing parameter estimation method. Default \"REML\", using Restricted Maximum Likelihood. See gam options. Ignored engine=\"glm\". ... anything else passed straight glm, gam, gamm bam.","code":""},{"path":"/reference/dsm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit a density surface model to segment-specific estimates of abundance or density. — dsm","text":"glm, gam, gamm bam object, additional element, $ddf holds detection function object.","code":""},{"path":"/reference/dsm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit a density surface model to segment-specific estimates of abundance or density. — dsm","text":"response (LHS formula) can one following (restrictions outlined ): count count segment abundance.est estimated abundance per segment, estimation via Horvitz-Thompson estimator density.est density per segment offset used model dependent response: count area segment multiplied average probability detection segment abundance.est area segment density zero count response can used detection function covariates vary segments/points (within). example, weather conditions (like visibility sea state) foliage cover usually acceptable change within segment, animal sex behaviour work. abundance.est response can used covariates detection function. density case, observations can weighted segment areas via weights= argument. default (weights=NULL), density estimated weights set segment areas (using segment.area calculated detection function object metadata Effort data). Alternatively weights=1 set weights equal. third alternative pass vector length equal number segments, containing appropriate weights. Example analyses available https://distancesampling.org/dsm/index.html.","code":""},{"path":"/reference/dsm.html","id":"units","dir":"Reference","previous_headings":"","what":"Units","title":"Fit a density surface model to segment-specific estimates of abundance or density. — dsm","text":"often case distances collected metres segment lengths recorded kilometres. dsm allows provide conversion factor (convert.units) multiply areas . example: distances metres segment lengths kilometres setting convert.units=1000 lead analysis metres. Setting convert.units=1/1000 lead analysis kilometres. conversion factor applied segment.area specified.","code":""},{"path":"/reference/dsm.html","id":"large-models","dir":"Reference","previous_headings":"","what":"Large models","title":"Fit a density surface model to segment-specific estimates of abundance or density. — dsm","text":"large models, engine=\"bam\" method=\"fREML\" may useful. Models specified bam gam. Read bam using option; option considered EXPERIMENTAL moment. particular note default basis choice (thin plate regression splines) slow general fitting less stable using gam. negative binomial response, theta must specified using bam.","code":""},{"path":"/reference/dsm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fit a density surface model to segment-specific estimates of abundance or density. — dsm","text":"Hedley, S. S. T. Buckland. 2004. Spatial models line transect sampling. JABES 9:181-199. Miller, D. L., Burt, M. L., Rexstad, E. ., Thomas, L. (2013), Spatial models distance sampling data: recent developments future directions. Methods Ecology Evolution, 4: 1001-1010. doi: 10.1111/2041-210X.12105 (Open Access) Wood, S.N. 2006. Generalized Additive Models: Introduction R. CRC/Chapman & Hall.","code":""},{"path":"/reference/dsm.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fit a density surface model to segment-specific estimates of abundance or density. — dsm","text":"David L. Miller","code":""},{"path":"/reference/dsm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit a density surface model to segment-specific estimates of abundance or density. — dsm","text":"","code":"if (FALSE) { # \\dontrun{ library(Distance) library(dsm)  # load the Gulf of Mexico dolphin data (see ?mexdolphins) data(mexdolphins)  # fit a detection function and look at the summary hr.model <- ds(distdata, truncation=6000,                key = \"hr\", adjustment = NULL) summary(hr.model)  # fit a simple smooth of x and y to counts mod1 <- dsm(count~s(x,y), hr.model, segdata, obsdata) summary(mod1)  # predict over a grid mod1.pred <- predict(mod1, preddata, preddata$area)  # calculate the predicted abundance over the grid sum(mod1.pred)  # plot the smooth plot(mod1) } # }"},{"path":"/reference/dsm.var.gam.html","id":null,"dir":"Reference","previous_headings":"","what":"Prediction variance estimation assuming independence — dsm.var.gam","title":"Prediction variance estimation assuming independence — dsm.var.gam","text":"function deprecated, use dsm_var_gam.","code":""},{"path":"/reference/dsm.var.gam.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prediction variance estimation assuming independence — dsm.var.gam","text":"","code":"dsm.var.gam(   dsm.obj,   pred.data,   off.set,   seglen.varname = \"Effort\",   type.pred = \"response\" )"},{"path":"/reference/dsm.var.gam.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prediction variance estimation assuming independence — dsm.var.gam","text":"dsm.obj model object fitted dsm. pred.data either: single prediction grid list prediction grids. grid data.frame columns original data. .set vector list vectors many elements pred.data. vector long number rows corresponding element pred.data. give area associated prediction cell. single number supplied replicated length pred.data. seglen.varname name column holds segment length (default value \"Effort\"). type.pred predictions \"response\" \"link\" scale? (default \"response\").","code":""},{"path":"/reference/dsm.var.movblk.html","id":null,"dir":"Reference","previous_headings":"","what":"Variance estimation via parametric moving block bootstrap — dsm.var.movblk","title":"Variance estimation via parametric moving block bootstrap — dsm.var.movblk","text":"function deprecated, use dsm_var_movblk.","code":""},{"path":"/reference/dsm.var.movblk.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Variance estimation via parametric moving block bootstrap — dsm.var.movblk","text":"","code":"dsm.var.movblk(   dsm.object,   pred.data,   n.boot,   block.size,   off.set,   ds.uncertainty = FALSE,   samp.unit.name = \"Transect.Label\",   progress.file = NULL,   bs.file = NULL,   bar = TRUE )"},{"path":"/reference/dsm.var.movblk.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Variance estimation via parametric moving block bootstrap — dsm.var.movblk","text":"dsm.object object returned dsm. pred.data either: single prediction grid list prediction grids. grid data.frame columns original data. n.boot number bootstrap resamples. block.size number segments block. .set vector list vectors many elements pred.data. vector long number rows corresponding element pred.data. give area associated prediction cell. single number supplied replicated length pred.data. ds.uncertainty incorporate uncertainty detection function? See Details, . Note feature EXPERIMENTAL moment. samp.unit.name name sampling unit resample (default 'Transect.Label'). progress.file path file used (usually Distance) generate progress bar (default NULL – file written). bs.file path file store bootstrap round. stores bootstrap results rather just summaries, enabling outliers detected removed. (Default NULL). bar progress bar printed screen? (Default TRUE).","code":""},{"path":"/reference/dsm.var.prop.html","id":null,"dir":"Reference","previous_headings":"","what":"Prediction variance propagation for DSMs — dsm.var.prop","title":"Prediction variance propagation for DSMs — dsm.var.prop","text":"function deprecated, use dsm_var_prop.","code":""},{"path":"/reference/dsm.var.prop.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prediction variance propagation for DSMs — dsm.var.prop","text":"","code":"dsm.var.prop(   dsm.obj,   pred.data,   off.set,   seglen.varname = \"Effort\",   type.pred = \"response\" )"},{"path":"/reference/dsm.var.prop.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prediction variance propagation for DSMs — dsm.var.prop","text":"dsm.obj model object fitted dsm. pred.data either: single prediction grid list prediction grids. grid data.frame columns original data. .set vector list vectors many elements pred.data. vector long number rows corresponding element pred.data. give area associated prediction cell. single number supplied replicated length pred.data. seglen.varname name column holds segment length (default value \"Effort\"). type.pred predictions \"response\" \"link\" scale? (default \"response\").","code":""},{"path":"/reference/dsm_cor.html","id":null,"dir":"Reference","previous_headings":"","what":"Check for autocorrelation in residuals — dsm_cor","title":"Check for autocorrelation in residuals — dsm_cor","text":"DSM fitted data, function can used check autocorrelation residuals.","code":""},{"path":"/reference/dsm_cor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check for autocorrelation in residuals — dsm_cor","text":"","code":"dsm_cor(   dsm.obj,   Transect.Label = \"Transect.Label\",   Segment.Label = \"Segment.Label\",   max.lag = 10,   resid.type = \"scaled.pearson\",   fun = cor,   ylim = c(0, 1),   subset = \"all\",   ... )"},{"path":"/reference/dsm_cor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check for autocorrelation in residuals — dsm_cor","text":"dsm.obj fitted dsm object. Transect.Label label transect (default: Transect.Label). Using different labels can useful transects split geographical features transects surveyed multiple times. Segment.Label label segments (default: Segment.Label).result calling order must make sense. max.lag maximum lag calculate . resid.type type residuals used, see residuals.gam. Defaults \"scaled.pearson\" GAM case \"normalized\" GAMM case (equivalent). fun function use, default cor, must take two column vectors arguments. ylim user defined limits y direction. subset subset data correlation function calculated ? ... options pass plot.","code":""},{"path":"/reference/dsm_cor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check for autocorrelation in residuals — dsm_cor","text":"plot vector fun applied lags.","code":""},{"path":"/reference/dsm_cor.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check for autocorrelation in residuals — dsm_cor","text":"Within Transect.Label, segments sorted according Segment.Labels. may require time get right particular data. one multiple surveys transects revisited, example, one may want make Transect.Label unique transect-survey identifier. Neither label need included model, must just present $data field model. usually means segment data passed dsm. current iteration function plot correlations nicely, things can get function return data (assigning result object). NA values residuals correlogram calculated. usually occurs due NA values covariates (smoother fitted values ). Code like (.na(dsm.obj$data)) might helpful.","code":""},{"path":"/reference/dsm_cor.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Check for autocorrelation in residuals — dsm_cor","text":"David L. Miller","code":""},{"path":"/reference/dsm_cor.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check for autocorrelation in residuals — dsm_cor","text":"","code":"# \\donttest{  library(Distance) #>  #> Attaching package: 'Distance' #> The following object is masked from 'package:dsm': #>  #>     dummy_ddf #> The following object is masked from 'package:mrds': #>  #>     create.bins  library(dsm)   # load the data, see ?mexdolphins  data(mexdolphins)   # fit a model  hr.model <- ds(distdata, truncation=6000,                 key = \"hr\", adjustment = NULL) #> Fitting hazard-rate key function #> AIC= 677.433 #> No survey area information supplied, only estimating detection function.  mod1 <- dsm(count~s(x,y), hr.model, segdata, obsdata) #> Warning: Some observations are outside of detection function 1 truncation!   # look at lag 1 differences up to a maximum of lag 9, using deviance  # residuals  dsm_cor(mod1, resid.type=\"deviance\", max.lag=9,          Segment.Label=\"Sample.Label\")  # }"},{"path":"/reference/dsm_varprop.html","id":null,"dir":"Reference","previous_headings":"","what":"Variance propagation for density surface models — dsm_varprop","title":"Variance propagation for density surface models — dsm_varprop","text":"Calculate uncertainty predictions fitted DSM, including uncertainty detection function.","code":""},{"path":"/reference/dsm_varprop.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Variance propagation for density surface models — dsm_varprop","text":"","code":"dsm_varprop(   model,   newdata = NULL,   trace = FALSE,   var.type = \"Vp\",   var_type = NULL )"},{"path":"/reference/dsm_varprop.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Variance propagation for density surface models — dsm_varprop","text":"model fitted dsm. newdata prediction grid. Set NULL avoid making predictions just return model objects. trace debugging, see scale parameter estimation going. var.type variance-covariance matrix used (\"Vp\" variance-covariance conditional smoothing parameter(s), \"Vc\" unconditional). See gamObject details/explanation. doubt, stick default, \"Vp\". var_type deprecated, use var.type instead.","code":""},{"path":"/reference/dsm_varprop.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Variance propagation for density surface models — dsm_varprop","text":"list elements: old_model fitted model supplied function model refit refitted model object, extra term pred point estimates predictions newdata var total variance calculated newdata ses standard error prediction cell newdata newdata=NULL last three entries NA.","code":""},{"path":"/reference/dsm_varprop.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Variance propagation for density surface models — dsm_varprop","text":"make predictions spatial model, also want know uncertainty abundance estimate. Since density surface models 2 () stage models, need incorporate uncertainty earlier stages (.e. detection function) \"final\" uncertainty estimate. function refit spatial model include Hessian offset extra term. Variance estimates using new model can used calculate variance predicted abundance estimates incorporate detection function uncertainty. Importantly requires detection function covariates, vary within segment (, example covariates like sex used). information construct prediction grid data.frame, newdata, see predict.dsm. routine useful detection function covariates used DSM. Note can use var.type=\"Vc\" (see gamObject), variance-covariance matrix spatial model, corrected smoothing parameter uncertainty. See Wood, Pya & Säfken (2016) information. Models fixed scale parameters (e.g., negative binomial) require extra round optimisation.","code":""},{"path":"/reference/dsm_varprop.html","id":"diagnostics","dir":"Reference","previous_headings":"","what":"Diagnostics","title":"Variance propagation for density surface models — dsm_varprop","text":"summary output function includes simply diagnostic shows average probability detection \"original\" fitted model (model supplied function; column Fitted.model) probability detection refitted model (used variance propagation; column Refitted.model) along standard error probability detection fitted model (Fitted.model.se), unique values factor covariates used detection function (continuous covariates 5%, 50% 95% quantiles shown). large differences probabilities detection potentially problems fitted model, variance propagation . can fitted model account enough variability data refitting variance model accounts random effect.","code":""},{"path":"/reference/dsm_varprop.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Variance propagation for density surface models — dsm_varprop","text":"Bravington, M. V., Miller, D. L., & Hedley, S. L. (2021). Variance Propagation Density Surface Models. Journal Agricultural, Biological Environmental Statistics. https://doi.org/10.1007/s13253-021-00438-2 Williams, R., Hedley, S.L., Branch, T.., Bravington, M.V., Zerbini, .N. Findlay, K.P. (2011). Chilean Blue Whales Case Study Illustrate Methods Estimate Abundance Evaluate Conservation Status Rare Species. Conservation Biology 25(3), 526-535. Wood, S.N., Pya, N. Säfken, B. (2016) Smoothing parameter model selection general smooth models. Journal American Statistical Association, 1-45.","code":""},{"path":"/reference/dsm_varprop.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Variance propagation for density surface models — dsm_varprop","text":"David L. Miller, based code Mark V. Bravington Sharon L. Hedley.","code":""},{"path":"/reference/dsm_var_gam.html","id":null,"dir":"Reference","previous_headings":"","what":"Prediction variance estimation assuming independence — dsm_var_gam","title":"Prediction variance estimation assuming independence — dsm_var_gam","text":"one willing assume detection function spatial model independent, function produce estimates variance predictions abundance, using result squared coefficients variation add.","code":""},{"path":"/reference/dsm_var_gam.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prediction variance estimation assuming independence — dsm_var_gam","text":"","code":"dsm_var_gam(   dsm.obj,   pred.data,   off.set,   seglen.varname = \"Effort\",   type.pred = \"response\" )"},{"path":"/reference/dsm_var_gam.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prediction variance estimation assuming independence — dsm_var_gam","text":"dsm.obj model object fitted dsm. pred.data either: single prediction grid list prediction grids. grid data.frame columns original data. .set vector list vectors many elements pred.data. vector long number rows corresponding element pred.data. give area associated prediction cell. single number supplied replicated length pred.data. seglen.varname name column holds segment length (default value \"Effort\"). type.pred predictions \"response\" \"link\" scale? (default \"response\").","code":""},{"path":"/reference/dsm_var_gam.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prediction variance estimation assuming independence — dsm_var_gam","text":"list elements model fitted model object pred.var variance regions given pred.data. bootstrap logical, always FALSE model fitted model extra term dsm.object original model (dsm.obj )","code":""},{"path":"/reference/dsm_var_gam.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Prediction variance estimation assuming independence — dsm_var_gam","text":"David L. Miller","code":""},{"path":"/reference/dsm_var_gam.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prediction variance estimation assuming independence — dsm_var_gam","text":"","code":"if (FALSE) { # \\dontrun{  library(Distance)  library(dsm)   # load the Gulf of Mexico dolphin data (see ?mexdolphins)  data(mexdolphins)   # fit a detection function and look at the summary  hr.model <- ds(distdata, truncation=6000,                 key = \"hr\", adjustment = NULL)  summary(hr.model)   # fit a simple smooth of x and y  mod1 <- dsm(count~s(x, y), hr.model, segdata, obsdata)   # Calculate the variance  # this will give a summary over the whole area in mexdolphins$preddata  mod1.var <- dsm_var_gam(mod1, preddata, off.set=preddata$area) } # }"},{"path":"/reference/dsm_var_movblk.html","id":null,"dir":"Reference","previous_headings":"","what":"Variance estimation via parametric moving block bootstrap — dsm_var_movblk","title":"Variance estimation via parametric moving block bootstrap — dsm_var_movblk","text":"Estimate variance abundance area using moving block bootstrap. Two procedures implemented, one incorporating detection function uncertainty, one .","code":""},{"path":"/reference/dsm_var_movblk.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Variance estimation via parametric moving block bootstrap — dsm_var_movblk","text":"","code":"dsm_var_movblk(   dsm.object,   pred.data,   n.boot,   block.size,   off.set,   ds.uncertainty = FALSE,   samp.unit.name = \"Transect.Label\",   progress.file = NULL,   bs.file = NULL,   bar = TRUE )"},{"path":"/reference/dsm_var_movblk.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Variance estimation via parametric moving block bootstrap — dsm_var_movblk","text":"dsm.object object returned dsm. pred.data either: single prediction grid list prediction grids. grid data.frame columns original data. n.boot number bootstrap resamples. block.size number segments block. .set vector list vectors many elements pred.data. vector long number rows corresponding element pred.data. give area associated prediction cell. single number supplied replicated length pred.data. ds.uncertainty incorporate uncertainty detection function? See Details, . Note feature EXPERIMENTAL moment. samp.unit.name name sampling unit resample (default 'Transect.Label'). progress.file path file used (usually Distance) generate progress bar (default NULL – file written). bs.file path file store bootstrap round. stores bootstrap results rather just summaries, enabling outliers detected removed. (Default NULL). bar progress bar printed screen? (Default TRUE).","code":""},{"path":"/reference/dsm_var_movblk.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Variance estimation via parametric moving block bootstrap — dsm_var_movblk","text":"Setting ds.uncertainty=TRUE incorporate detection function uncertainty directly bootstrap. done generating observations fitted detection function re-fitting new detection function (form), calculating new effective strip width. Rejection sampling used generate observations (except half-normal case) procedure can rather slow. Note currently supported covariates detection function. Setting ds.uncertainty=FALSE incorporate detection function uncertainty using delta method. assumes detection function spatial model INDEPENDENT. probably reasonable.","code":""},{"path":"/reference/dsm_var_movblk.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Variance estimation via parametric moving block bootstrap — dsm_var_movblk","text":"","code":"if (FALSE) { # \\dontrun{ library(Distance) library(dsm)  # load the Gulf of Mexico dolphin data (see ?mexdolphins) data(mexdolphins)  # fit a detection function and look at the summary hr.model <- ds(distdata, truncation=6000,                key = \"hr\", adjustment = NULL) summary(hr.model)  # fit a simple smooth of x and y mod1 <- dsm(count~s(x, y), hr.model, segdata, obsdata) summary(mod1)  # calculate the variance by 500 moving block bootstraps mod1.movblk <- dsm_var_movblk(mod1, preddata, n.boot = 500,    block.size = 3, samp.unit.name = \"Transect.Label\",    off.set = preddata$area,    bar = TRUE, bs.file = \"mexico-bs.csv\", ds.uncertainty = TRUE) } # }"},{"path":"/reference/dsm_var_prop.html","id":null,"dir":"Reference","previous_headings":"","what":"Prediction variance propagation for DSMs — dsm_var_prop","title":"Prediction variance propagation for DSMs — dsm_var_prop","text":"ensure uncertainty detection function correctly propagated final variance estimate abundance, function uses method first detailed Williams et al (2011), explanation given Bravington et al. (2021).","code":""},{"path":"/reference/dsm_var_prop.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prediction variance propagation for DSMs — dsm_var_prop","text":"","code":"dsm_var_prop(   dsm.obj,   pred.data,   off.set,   seglen.varname = \"Effort\",   type.pred = \"response\" )"},{"path":"/reference/dsm_var_prop.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prediction variance propagation for DSMs — dsm_var_prop","text":"dsm.obj model object fitted dsm. pred.data either: single prediction grid list prediction grids. grid data.frame columns original data. .set vector list vectors many elements pred.data. vector long number rows corresponding element pred.data. give area associated prediction cell. single number supplied replicated length pred.data. seglen.varname name column holds segment length (default value \"Effort\"). type.pred predictions \"response\" \"link\" scale? (default \"response\").","code":""},{"path":"/reference/dsm_var_prop.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prediction variance propagation for DSMs — dsm_var_prop","text":"list elements model fitted model object pred.var variance region given pred.data bootstrap logical, always FALSE pred.data .set model fitted model extra term dsm.object original model, model.check simple check subtracting coefficients two models see large difference deriv numerically calculated Hessian offset","code":""},{"path":"/reference/dsm_var_prop.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Prediction variance propagation for DSMs — dsm_var_prop","text":"idea refit spatial model including extra random effect. random effect zero mean hence effect point estimates. variance Hessian detection function. Variance estimates incorporate detection function uncertainty. mathematical details given paper references . Many prediction grids can supplied supplying list data.frames function. Note routine simply calls dsm_varprop. require multiple prediction grids, routine probably faster. routine useful detection function covariates used DSM.","code":""},{"path":"/reference/dsm_var_prop.html","id":"diagnostics","dir":"Reference","previous_headings":"","what":"Diagnostics","title":"Prediction variance propagation for DSMs — dsm_var_prop","text":"summary output function includes simply diagnostic shows average probability detection \"original\" fitted model (model supplied function; column Fitted.model) probability detection refitted model (used variance propagation; column Refitted.model) along standard error probability detection fitted model (Fitted.model.se), unique values factor covariates used detection function (continuous covariates 5%, 50% 95% quantiles shown). large differences probabilities detection potentially problems fitted model, variance propagation . can fitted model account enough variability data refitting variance model accounts random effect.","code":""},{"path":"/reference/dsm_var_prop.html","id":"limitations","dir":"Reference","previous_headings":"","what":"Limitations","title":"Prediction variance propagation for DSMs — dsm_var_prop","text":"Note routine useful detection function used DSM. used abundance.est density.est responses used. Importantly requires detection function covariates, vary within segment (, example covariates like sex used).","code":""},{"path":"/reference/dsm_var_prop.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Prediction variance propagation for DSMs — dsm_var_prop","text":"Bravington, M. V., Miller, D. L., & Hedley, S. L. (2021). Variance Propagation Density Surface Models. Journal Agricultural, Biological Environmental Statistics. https://doi.org/10.1007/s13253-021-00438-2 Williams, R., Hedley, S.L., Branch, T.., Bravington, M.V., Zerbini, .N. Findlay, K.P. (2011). Chilean Blue Whales Case Study Illustrate Methods Estimate Abundance Evaluate Conservation Status Rare Species. Conservation Biology 25(3), 526-535.","code":""},{"path":"/reference/dsm_var_prop.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Prediction variance propagation for DSMs — dsm_var_prop","text":"Mark V. Bravington, Sharon L. Hedley. Bugs added David L. Miller.","code":""},{"path":"/reference/dummy_ddf.html","id":null,"dir":"Reference","previous_headings":"","what":"Detection function objects when detection is certain — dummy_ddf","title":"Detection function objects when detection is certain — dummy_ddf","text":"Create detection function object strip/plot surveys use density surface models.","code":""},{"path":"/reference/dummy_ddf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detection function objects when detection is certain — dummy_ddf","text":"","code":"dummy_ddf(object, size = 1, width, left = 0, transect = \"line\")"},{"path":"/reference/dummy_ddf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Detection function objects when detection is certain — dummy_ddf","text":"object numeric vector object identifiers, relating object field observation data DSM. size group size observation (default groups size 1) width right truncation left left truncation (default 0, left truncation) transect \"line\" \"point\" transect","code":""},{"path":"/reference/dummy_ddf.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Detection function objects when detection is certain — dummy_ddf","text":"David L Miller","code":""},{"path":"/reference/generate.ds.uncertainty.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate data from a fitted detection function — generate.ds.uncertainty","title":"Generate data from a fitted detection function — generate.ds.uncertainty","text":"using dsm.var.movblk ds.uncertainty=TRUE, procedure generates data fitted detection function (assuming correct).","code":""},{"path":"/reference/generate.ds.uncertainty.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate data from a fitted detection function — generate.ds.uncertainty","text":"","code":"generate.ds.uncertainty(ds.object)"},{"path":"/reference/generate.ds.uncertainty.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate data from a fitted detection function — generate.ds.uncertainty","text":"ds.object fitted detection function object (returned call ddf.ds).","code":""},{"path":"/reference/generate.ds.uncertainty.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Generate data from a fitted detection function — generate.ds.uncertainty","text":"function changes random number generator seed. avoid potential side-effects, use something like: seed <- get(\".Random.seed\",envir=.GlobalEnv) running code assign(\".Random.seed\",seed,envir=.GlobalEnv) .","code":""},{"path":"/reference/generate.ds.uncertainty.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Generate data from a fitted detection function — generate.ds.uncertainty","text":"David L. Miller","code":""},{"path":"/reference/generate.mb.sample.html","id":null,"dir":"Reference","previous_headings":"","what":"Moving block bootstrap sampler — generate.mb.sample","title":"Moving block bootstrap sampler — generate.mb.sample","text":"usually used , called within dsm.var.movblk.","code":""},{"path":"/reference/generate.mb.sample.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Moving block bootstrap sampler — generate.mb.sample","text":"","code":"generate.mb.sample(   num.blocks.required,   block.size,   which.blocks,   dsm.data,   unit.info,   n.units )"},{"path":"/reference/generate.mb.sample.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Moving block bootstrap sampler — generate.mb.sample","text":"num.blocks.required number blocks need. block.size number segments per block. .blocks blocks sampled. dsm.data $data element result call dsm. unit.info result calling block.info.per.su. n.units number sampling units.","code":""},{"path":"/reference/generate.mb.sample.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Moving block bootstrap sampler — generate.mb.sample","text":"vector log-residuals","code":""},{"path":"/reference/latlong2km.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert latitude and longitude to Northings and Eastings — latlong2km","title":"Convert latitude and longitude to Northings and Eastings — latlong2km","text":"Convert longitude latitude co-ordinates kilometres west-east south-north axes (lon0,lat0) using \"spherical law cosines\".","code":""},{"path":"/reference/latlong2km.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert latitude and longitude to Northings and Eastings — latlong2km","text":"","code":"latlong2km(lon, lat, lon0 = sum(range(lon))/2, lat0 = sum(range(lat))/2)"},{"path":"/reference/latlong2km.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert latitude and longitude to Northings and Eastings — latlong2km","text":"lon longitude lat latitude lon0 longitude reference point (defaults mean longitude) lat0 latitude reference point (defaults mean latitude)","code":""},{"path":"/reference/latlong2km.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert latitude and longitude to Northings and Eastings — latlong2km","text":"list elements km.e km.n.","code":""},{"path":"/reference/latlong2km.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert latitude and longitude to Northings and Eastings — latlong2km","text":"WARNING: approximate procedure converting latitude/ longitude Northing/Easting. Consider using projection conversions available packages sp, sf rgdal better results.","code":""},{"path":"/reference/latlong2km.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert latitude and longitude to Northings and Eastings — latlong2km","text":"Simon N. Wood","code":""},{"path":"/reference/make.soapgrid.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a knot grid for the internal part of a soap film smoother. — make.soapgrid","title":"Create a knot grid for the internal part of a soap film smoother. — make.soapgrid","text":"routine simply creates grid knots (correct format) used \"internal\" part soap film smoother","code":""},{"path":"/reference/make.soapgrid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a knot grid for the internal part of a soap film smoother. — make.soapgrid","text":"","code":"make.soapgrid(bnd, n.grid)"},{"path":"/reference/make.soapgrid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a knot grid for the internal part of a soap film smoother. — make.soapgrid","text":"bnd list elements x y give locations boundary vertices. first last elements . n.grid either one number giving number points along x y axes used create grid, vector giving number x direction, y direction.","code":""},{"path":"/reference/make.soapgrid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a knot grid for the internal part of a soap film smoother. — make.soapgrid","text":"list elements x y, containing knot locations.","code":""},{"path":"/reference/make.soapgrid.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Create a knot grid for the internal part of a soap film smoother. — make.soapgrid","text":"David L Miller","code":""},{"path":"/reference/mexdolphins.html","id":null,"dir":"Reference","previous_headings":"","what":"Pan-tropical spotted dolphins in the Gulf of Mexico — mexdolphins","title":"Pan-tropical spotted dolphins in the Gulf of Mexico — mexdolphins","text":"Data combination several NOAA shipboard surveys conducted pan-tropical spotted dolphins Gulf Mexico. data consist 47 observations groups dolphins. group size recorded, well Beaufort sea state time observation. Coordinates observation bathymetry data also available covariates analysis. complete example analysis (description data) provided articles https://distancesampling.org/dsm/index.html.","code":""},{"path":"/reference/mexdolphins.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Pan-tropical spotted dolphins in the Gulf of Mexico — mexdolphins","text":"Halpin, P.N., .J. Read, E. Fujioka, B.D. Best, B. Donnelly, L.J. Hazen, C. Kot, K. Urian, E. LaBrecque, . Dimatteo, J. Cleary, C. Good, L.B. Crowder, K.D. Hyrenbach. 2009. OBIS-SEAMAP: world data center marine mammal, sea bird, sea turtle distributions. Oceanography 22(2):104-115 NOAA Southeast Fisheries Science Center. 1996. Report Cetacean Survey Oceanic Selected Continental Shelf Waters Northern Gulf Mexico aboard NOAA Ship Oregon II (Cruise 220)","code":""},{"path":"/reference/obs_exp.html","id":null,"dir":"Reference","previous_headings":"","what":"Observed versus expected diagnostics for fitted DSMs — obs_exp","title":"Observed versus expected diagnostics for fitted DSMs — obs_exp","text":"Given covariate, calculate observed expected counts unique value covariate. can useful goodness fit check DSMs.","code":""},{"path":"/reference/obs_exp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Observed versus expected diagnostics for fitted DSMs — obs_exp","text":"","code":"obs_exp(model, covar, cut = NULL)"},{"path":"/reference/obs_exp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Observed versus expected diagnostics for fitted DSMs — obs_exp","text":"model fitted dsm model object covar covariate aggregate (character) cut vector cut points aggregate . supplied, unique values covar used.","code":""},{"path":"/reference/obs_exp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Observed versus expected diagnostics for fitted DSMs — obs_exp","text":"data.frame values observed expected counts.","code":""},{"path":"/reference/obs_exp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Observed versus expected diagnostics for fitted DSMs — obs_exp","text":"One strategy model checking calculate observed expected counts different aggregations variable. match well model fit good.","code":""},{"path":"/reference/obs_exp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Observed versus expected diagnostics for fitted DSMs — obs_exp","text":"David L Miller, suggestion Mark Bravington.","code":""},{"path":"/reference/obs_exp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Observed versus expected diagnostics for fitted DSMs — obs_exp","text":"","code":"if (FALSE) { # \\dontrun{ library(Distance) library(dsm)  # example with the Gulf of Mexico dolphin data data(mexdolphins) hr.model <- ds(distdata, truncation=6000,                key = \"hr\", adjustment = NULL) mod1 <- dsm(count~s(x,y), hr.model, segdata, obsdata) } # }"},{"path":"/reference/plot.dsm.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot a density surface model. — plot.dsm","title":"Plot a density surface model. — plot.dsm","text":"See plot.gam.","code":""},{"path":"/reference/plot.dsm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a density surface model. — plot.dsm","text":"","code":"# S3 method for class 'dsm' plot(x, ...)"},{"path":"/reference/plot.dsm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a density surface model. — plot.dsm","text":"x model fitted dsm ... arguments passed plot.gam.","code":""},{"path":"/reference/plot.dsm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot a density surface model. — plot.dsm","text":"plot!","code":""},{"path":[]},{"path":"/reference/plot.dsm.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot a density surface model. — plot.dsm","text":"David L. Miller","code":""},{"path":"/reference/plot.dsm.var.html","id":null,"dir":"Reference","previous_headings":"","what":"Create plots of abundance uncertainty — plot.dsm.var","title":"Create plots of abundance uncertainty — plot.dsm.var","text":"Note prediction data set must x y columns even used model.","code":""},{"path":"/reference/plot.dsm.var.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create plots of abundance uncertainty — plot.dsm.var","text":"","code":"# S3 method for class 'dsm.var' plot(   x,   poly = NULL,   limits = NULL,   breaks = NULL,   legend.breaks = NULL,   xlab = \"x\",   ylab = \"y\",   observations = TRUE,   plot = TRUE,   boxplot.coef = 1.5,   x.name = \"x\",   y.name = \"y\",   gg.grad = NULL,   ... )"},{"path":"/reference/plot.dsm.var.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create plots of abundance uncertainty — plot.dsm.var","text":"x dsm.var object poly list data.frame columns x y, gives coordinates polygon draw. may also optionally column group, many polygons. limits limits fill colours breaks breaks colour fill legend.breaks breaks displayed xlab label x axis ylab label y axis observations observations plotted? plot actually plot map, just return ggplot2 object? boxplot.coef control trimming (summary.dsm.var), effect bootstrap file saved. x.name name variable plot x axis. y.name name variable plot y axis. gg.grad optional ggplot gradient object. ... arguments","code":""},{"path":"/reference/plot.dsm.var.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create plots of abundance uncertainty — plot.dsm.var","text":"plot","code":""},{"path":"/reference/plot.dsm.var.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create plots of abundance uncertainty — plot.dsm.var","text":"order get plotting work dsm_var_prop dsm_var_gam, one must first format data correctly since functions designed compute general summaries. One summary calculated element list pred supplied dsm_var_prop dsm_var_gam. plot uncertainty prediction grid, pred (data.frame), say, can create correct format simply using pred.new <- split(pred,1:nrow(pred)).","code":""},{"path":[]},{"path":"/reference/plot.dsm.var.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Create plots of abundance uncertainty — plot.dsm.var","text":"David L. Miller","code":""},{"path":"/reference/plot_pred_by_term.html","id":null,"dir":"Reference","previous_headings":"","what":"Spatially plot predictions per model term — plot_pred_by_term","title":"Spatially plot predictions per model term — plot_pred_by_term","text":"Plot effect smooth model spatially. term model, plot effect space. Plots made scale, relative influence smooth can seen.","code":""},{"path":"/reference/plot_pred_by_term.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Spatially plot predictions per model term — plot_pred_by_term","text":"","code":"plot_pred_by_term(dsm.obj, data, location.cov = c(\"x\", \"y\"))"},{"path":"/reference/plot_pred_by_term.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Spatially plot predictions per model term — plot_pred_by_term","text":"dsm.obj fitted dsm object data data use plot (often prediction grid), data also include width height columns plotting location.cov deprecated, use location.cov","code":""},{"path":"/reference/plot_pred_by_term.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Spatially plot predictions per model term — plot_pred_by_term","text":"ggplot2 plot","code":""},{"path":"/reference/plot_pred_by_term.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Spatially plot predictions per model term — plot_pred_by_term","text":"David L Miller (idea taken inlabru)","code":""},{"path":"/reference/plot_pred_by_term.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Spatially plot predictions per model term — plot_pred_by_term","text":"","code":"if (FALSE) { # \\dontrun{ library(Distance) library(dsm)  # load the Gulf of Mexico dolphin data and fit a model data(mexdolphins) hr.model <- ds(distdata, truncation=6000,                key = \"hr\", adjustment = NULL) mod1 <- dsm(count~s(x,y) + s(depth), hr.model, segdata, obsdata)  preddata$width <- preddata$height <- sqrt(preddata$area)  # make the plot plot_pred_by_term(mod1, preddata, c(\"x\",\"y\"))  # better plot would be # library(viridis) # plot_pred_by_term(mod1, preddata, c(\"x\",\"y\")) + scale_fill_viridis() } # }"},{"path":"/reference/predict.dsm.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict from a fitted density surface model — predict.dsm","title":"Predict from a fitted density surface model — predict.dsm","text":"Make predictions density abundance outside (inside) covered area.","code":""},{"path":"/reference/predict.dsm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict from a fitted density surface model — predict.dsm","text":"","code":"# S3 method for class 'dsm' predict(object, newdata = NULL, off.set = NULL, type = \"response\", ...)"},{"path":"/reference/predict.dsm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict from a fitted density surface model — predict.dsm","text":"object fitted dsm object newdata spatially referenced covariates e.g. altitude, depth, distance shore, etc. Covariates data.frame must names identical variable names used fitting model .set area cells prediction grid. units segments/distances given dsm. Replaces column newdata called .set supplied. Ignored newdata supplied type scale results . default \"response\", see predict.gam explanation options (usually necessary) ... arguments passed predict.gam","code":""},{"path":"/reference/predict.dsm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predict from a fitted density surface model — predict.dsm","text":"predicted values response scale default (unless type specified, case see predict.gam).","code":""},{"path":"/reference/predict.dsm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Predict from a fitted density surface model — predict.dsm","text":"newdata supplied, predictions made data built model. Note order results necessarily segdata (segment data) data.frame supplied dsm. area .set used argument supplied, otherwise look areas column named .set newdata. Either way link function (usually log) applied offsets, need log passing function.","code":""},{"path":[]},{"path":"/reference/predict.dsm.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Predict from a fitted density surface model — predict.dsm","text":"David L. Miller","code":""},{"path":"/reference/predict.fake_ddf.html","id":null,"dir":"Reference","previous_headings":"","what":"Prediction for fake detection functions — predict.fake_ddf","title":"Prediction for fake detection functions — predict.fake_ddf","text":"Prediction function dummy detection functions. function returns many 1s rows newdata. esw=TRUE strip width returned.","code":""},{"path":"/reference/predict.fake_ddf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prediction for fake detection functions — predict.fake_ddf","text":"","code":"# S3 method for class 'fake_ddf' predict(   object,   newdata = NULL,   compute = FALSE,   int.range = NULL,   esw = FALSE,   ... )"},{"path":"/reference/predict.fake_ddf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prediction for fake detection functions — predict.fake_ddf","text":"object model object newdata many 1s return? compute unused, compatibility mrds::predict int.range unused, compatibility mrds::predict esw strip width returned? ... S3 consistency","code":""},{"path":"/reference/predict.fake_ddf.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Prediction for fake detection functions — predict.fake_ddf","text":"David L Miller","code":""},{"path":"/reference/print.dsm.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a description of a density surface model object — print.dsm","title":"Print a description of a density surface model object — print.dsm","text":"method just gives short description fitted model. Use summary.dsm method information.","code":""},{"path":"/reference/print.dsm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a description of a density surface model object — print.dsm","text":"","code":"# S3 method for class 'dsm' print(x, ...)"},{"path":"/reference/print.dsm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a description of a density surface model object — print.dsm","text":"x model fitted dsm ... unspecified unused arguments S3 consistency","code":""},{"path":"/reference/print.dsm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print a description of a density surface model object — print.dsm","text":"NULL","code":""},{"path":"/reference/print.dsm.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print a description of a density surface model object — print.dsm","text":"David L. Miller","code":""},{"path":"/reference/print.dsm.var.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a description of a density surface model variance object — print.dsm.var","title":"Print a description of a density surface model variance object — print.dsm.var","text":"method provides short summary, use summary.dsm.var method information.","code":""},{"path":"/reference/print.dsm.var.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a description of a density surface model variance object — print.dsm.var","text":"","code":"# S3 method for class 'dsm.var' print(x, ...)"},{"path":"/reference/print.dsm.var.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a description of a density surface model variance object — print.dsm.var","text":"x dsm variance object ... unspecified unused arguments S3 consistency","code":""},{"path":"/reference/print.dsm.var.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print a description of a density surface model variance object — print.dsm.var","text":"NULL","code":""},{"path":[]},{"path":"/reference/print.dsm.var.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print a description of a density surface model variance object — print.dsm.var","text":"David L. Miller","code":""},{"path":"/reference/print.dsm_varprop.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a description of a density surface model variance object — print.dsm_varprop","title":"Print a description of a density surface model variance object — print.dsm_varprop","text":"method provides short summary, see summary.dsm_varprop.","code":""},{"path":"/reference/print.dsm_varprop.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a description of a density surface model variance object — print.dsm_varprop","text":"","code":"# S3 method for class 'dsm_varprop' print(x, ...)"},{"path":"/reference/print.dsm_varprop.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a description of a density surface model variance object — print.dsm_varprop","text":"x dsm variance object ... unspecified unused arguments S3 consistency","code":""},{"path":[]},{"path":"/reference/print.dsm_varprop.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print a description of a density surface model variance object — print.dsm_varprop","text":"David L. Miller","code":""},{"path":"/reference/print.summary.dsm.var.html","id":null,"dir":"Reference","previous_headings":"","what":"Print summary of density surface model variance object — print.summary.dsm.var","title":"Print summary of density surface model variance object — print.summary.dsm.var","text":"See summary.dsm.var information.","code":""},{"path":"/reference/print.summary.dsm.var.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print summary of density surface model variance object — print.summary.dsm.var","text":"","code":"# S3 method for class 'summary.dsm.var' print(x, ...)"},{"path":"/reference/print.summary.dsm.var.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print summary of density surface model variance object — print.summary.dsm.var","text":"x summary dsm variance object ... unspecified unused arguments S3 consistency","code":""},{"path":"/reference/print.summary.dsm.var.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print summary of density surface model variance object — print.summary.dsm.var","text":"NULL","code":""},{"path":[]},{"path":"/reference/print.summary.dsm.var.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print summary of density surface model variance object — print.summary.dsm.var","text":"David L. Miller","code":""},{"path":"/reference/print.summary.dsm_varprop.html","id":null,"dir":"Reference","previous_headings":"","what":"Print summary of density surface model variance object — print.summary.dsm_varprop","title":"Print summary of density surface model variance object — print.summary.dsm_varprop","text":"See summary.dsm_varprop information.","code":""},{"path":"/reference/print.summary.dsm_varprop.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print summary of density surface model variance object — print.summary.dsm_varprop","text":"","code":"# S3 method for class 'summary.dsm_varprop' print(x, ...)"},{"path":"/reference/print.summary.dsm_varprop.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print summary of density surface model variance object — print.summary.dsm_varprop","text":"x summary dsm variance object ... unspecified unused arguments S3 consistency","code":""},{"path":"/reference/print.summary.dsm_varprop.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print summary of density surface model variance object — print.summary.dsm_varprop","text":"NULL","code":""},{"path":[]},{"path":"/reference/print.summary.dsm_varprop.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print summary of density surface model variance object — print.summary.dsm_varprop","text":"David L. Miller","code":""},{"path":"/reference/rqgam.check.html","id":null,"dir":"Reference","previous_headings":"","what":"Randomised quantile residuals check plot for GAMs/DSMs — rqgam.check","title":"Randomised quantile residuals check plot for GAMs/DSMs — rqgam.check","text":"function deprecated, use rqgam_check.","code":""},{"path":"/reference/rqgam.check.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Randomised quantile residuals check plot for GAMs/DSMs — rqgam.check","text":"","code":"rqgam.check(gam.obj, ...)"},{"path":"/reference/rqgam.check.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Randomised quantile residuals check plot for GAMs/DSMs — rqgam.check","text":"gam.obj gam, glm dsm object. ... arguments passed plotting functions","code":""},{"path":"/reference/rqgam_check.html","id":null,"dir":"Reference","previous_headings":"","what":"Randomised quantile residuals check plot for GAMs/DSMs — rqgam_check","title":"Randomised quantile residuals check plot for GAMs/DSMs — rqgam_check","text":"Reproduces \"Resids vs. linear pred\" plot gam.check using randomised quantile residuals, la Dunn Smyth (1996). Checks heteroskedasticity usual, looking \"funnel\"-type structures points, much easier randomised quantile residuals deviance residuals, model uses count distribution response.","code":""},{"path":"/reference/rqgam_check.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Randomised quantile residuals check plot for GAMs/DSMs — rqgam_check","text":"","code":"rqgam_check(gam.obj, ...)"},{"path":"/reference/rqgam_check.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Randomised quantile residuals check plot for GAMs/DSMs — rqgam_check","text":"gam.obj gam, glm dsm object. ... arguments passed plotting functions","code":""},{"path":"/reference/rqgam_check.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Randomised quantile residuals check plot for GAMs/DSMs — rqgam_check","text":"just plots!","code":""},{"path":"/reference/rqgam_check.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Randomised quantile residuals check plot for GAMs/DSMs — rqgam_check","text":"Note function works negative binomial Tweedie response distributions. Earlier versions function produced full gam.check output, confusing one plots really useful.  Checks k computed, need done using gam.check.","code":""},{"path":"/reference/rqgam_check.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Randomised quantile residuals check plot for GAMs/DSMs — rqgam_check","text":"Based code Natalie Kelly, bugs added Dave Miller","code":""},{"path":"/reference/rqgam_check.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Randomised quantile residuals check plot for GAMs/DSMs — rqgam_check","text":"","code":"# \\donttest{ library(Distance) library(dsm) library(tweedie)  # load the Gulf of Mexico dolphin data (see ?mexdolphins) data(mexdolphins)  # fit a detection function and look at the summary hr.model <- ds(distdata, truncation=6000,                key = \"hr\", adjustment = NULL) #> Fitting hazard-rate key function #> AIC= 677.433 #> No survey area information supplied, only estimating detection function.  # fit a simple smooth of x and y with a Tweedie response with estimated #  p parameter mod1 <- dsm(count~s(x, y), hr.model, segdata, obsdata, family=tw()) #> Warning: Some observations are outside of detection function 1 truncation! rqgam_check(mod1)  # }"},{"path":"/reference/summary.dsm.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize a fitted density surface model — summary.dsm","title":"Summarize a fitted density surface model — summary.dsm","text":"Gives brief summary fitted dsm object.","code":""},{"path":"/reference/summary.dsm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize a fitted density surface model — summary.dsm","text":"","code":"# S3 method for class 'dsm' summary(object, ...)"},{"path":"/reference/summary.dsm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize a fitted density surface model — summary.dsm","text":"object model fitted dsm ... arguments passed summary.gam","code":""},{"path":"/reference/summary.dsm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize a fitted density surface model — summary.dsm","text":"summary object","code":""},{"path":[]},{"path":"/reference/summary.dsm.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Summarize a fitted density surface model — summary.dsm","text":"David L. Miller","code":""},{"path":"/reference/summary.dsm.var.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize the variance of a density surface model — summary.dsm.var","title":"Summarize the variance of a density surface model — summary.dsm.var","text":"Gives brief summary fitted dsm variance object.","code":""},{"path":"/reference/summary.dsm.var.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize the variance of a density surface model — summary.dsm.var","text":"","code":"# S3 method for class 'dsm.var' summary(   object,   alpha = 0.05,   boxplot.coef = 1.5,   bootstrap.subregions = NULL,   ... )"},{"path":"/reference/summary.dsm.var.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize the variance of a density surface model — summary.dsm.var","text":"object dsm.var object alpha alpha level confidence intervals (default 0.05 give 95\\ confidence intervals) boxplot.coef value coef used calculate outliers see boxplot. bootstrap.subregions list vectors logicals indices subregions variances need calculated (bootstraps (see dsm.var.prop use subregions variance propagation). ... unused arguments S3 compatibility","code":""},{"path":"/reference/summary.dsm.var.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize the variance of a density surface model — summary.dsm.var","text":"summary object","code":""},{"path":[]},{"path":"/reference/summary.dsm.var.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Summarize the variance of a density surface model — summary.dsm.var","text":"David L. Miller","code":""},{"path":"/reference/summary.dsm_varprop.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize the variance of a density surface model — summary.dsm_varprop","title":"Summarize the variance of a density surface model — summary.dsm_varprop","text":"Gives brief summary fitted dsm_varprop variance object.","code":""},{"path":"/reference/summary.dsm_varprop.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize the variance of a density surface model — summary.dsm_varprop","text":"","code":"# S3 method for class 'dsm_varprop' summary(object, alpha = 0.05, ...)"},{"path":"/reference/summary.dsm_varprop.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize the variance of a density surface model — summary.dsm_varprop","text":"object dsm.var object alpha alpha level confidence intervals (default 0.05 give 95% confidence internal) ... unused arguments S3 compatibility","code":""},{"path":"/reference/summary.dsm_varprop.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize the variance of a density surface model — summary.dsm_varprop","text":"summary object","code":""},{"path":[]},{"path":"/reference/summary.dsm_varprop.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Summarize the variance of a density surface model — summary.dsm_varprop","text":"David L. Miller","code":""},{"path":"/reference/trim.var.html","id":null,"dir":"Reference","previous_headings":"","what":"Trimmed variance — trim.var","title":"Trimmed variance — trim.var","text":"Trim variance estimates bootstrap. defined percentage defined amount necessary bring median trimmed mean within 8% defined 'outliers'.","code":""},{"path":"/reference/trim.var.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Trimmed variance — trim.var","text":"","code":"trim.var(untrimmed.bootstraps, boxplot.coef = 1.5)"},{"path":"/reference/trim.var.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Trimmed variance — trim.var","text":"untrimmed.bootstraps (usually $study.area.total element returned dsm.var.movblk bootstrap object. boxplot.coef value coef used calculate outliers see boxplot.","code":""},{"path":"/reference/trim.var.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Trimmed variance — trim.var","text":"trimmed variance","code":""},{"path":"/reference/trim.var.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Trimmed variance — trim.var","text":"Louise Burt","code":""},{"path":"/reference/vis.concurvity.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualise concurvity between terms in a GAM — vis.concurvity","title":"Visualise concurvity between terms in a GAM — vis.concurvity","text":"function deprecated, use vis_concurvity.","code":""},{"path":"/reference/vis.concurvity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualise concurvity between terms in a GAM — vis.concurvity","text":"","code":"vis.concurvity(model, type = \"estimate\")"},{"path":"/reference/vis.concurvity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualise concurvity between terms in a GAM — vis.concurvity","text":"model fitted model type concurvity measure plot, see concurvity","code":""},{"path":"/reference/vis_concurvity.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualise concurvity between terms in a GAM — vis_concurvity","title":"Visualise concurvity between terms in a GAM — vis_concurvity","text":"Plot measures much one term model explained another. values high, one consider re-running variable selection one offending variables removed check stability term selection.","code":""},{"path":"/reference/vis_concurvity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualise concurvity between terms in a GAM — vis_concurvity","text":"","code":"vis_concurvity(model, type = \"estimate\")"},{"path":"/reference/vis_concurvity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualise concurvity between terms in a GAM — vis_concurvity","text":"model fitted model type concurvity measure plot, see concurvity","code":""},{"path":"/reference/vis_concurvity.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Visualise concurvity between terms in a GAM — vis_concurvity","text":"methods considered somewhat experimental time. Consult concurvity information concurvity measures calculated.","code":""},{"path":"/reference/vis_concurvity.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Visualise concurvity between terms in a GAM — vis_concurvity","text":"David L Miller","code":""},{"path":"/reference/vis_concurvity.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Visualise concurvity between terms in a GAM — vis_concurvity","text":"","code":"if (FALSE) { # \\dontrun{ library(Distance) library(dsm)  # load the Gulf of Mexico dolphin data (see ?mexdolphins) data(mexdolphins)  # fit a detection function and look at the summary hr.model <- ds(distdata, truncation=6000,                key = \"hr\", adjustment = NULL)  # fit a simple smooth of x and y to counts mod1 <- dsm(count~s(x,y)+s(depth), hr.model, segdata, obsdata)  # visualise concurvity using the \"estimate\" metric vis_concurvity(mod1) } # }"},{"path":"/news/index.html","id":"dsm-234","dir":"Changelog","previous_headings":"","what":"dsm 2.3.4","title":"dsm 2.3.4","text":"fix bug predictions NA (e.g., predictions outside soap boundary), variances NA due propagation (#4) fix CRAN NOTES regarding documentation links special characters.","code":""},{"path":"/news/index.html","id":"dsm-233","dir":"Changelog","previous_headings":"","what":"dsm 2.3.3","title":"dsm 2.3.3","text":"CRAN release: 2022-08-20 dsm.var.prop -> dsm_var_prop dsm.var.gam -> dsm_var_gam dsm.var.movblk -> dsm_var_movblk dsm.cor -> dsm_cor rqgam.check -> rqgam_check vis.concurvity -> vis_concurvity var_type -> var.type","code":""},{"path":"/news/index.html","id":"dsm-232","dir":"Changelog","previous_headings":"","what":"dsm 2.3.2","title":"dsm 2.3.2","text":"CRAN release: 2022-03-17 fixed bug offset calculation dsm_varprop se estimation offsets logged twice. Thanks Megan Ferguson spotting . documentation now rmarkdown format dsm 2.3.1 transect type (line point) now determined detection function rather using transect= argument multiple detection functions now possible, use list() fitted detection functions supplied ddf.obj= argument dsm(). dsm.var.gam, dsm.var.prop dsm_varprop compatible. Vignette coming soon. Thanks Dave Fifield Ewan Wakefield extensive testing suggestions. See ?“dsm-data” information set data. strip transects now handled using dummy_ddf() function. presence~ response type removed Response options “D”, “density”, “Dhat”, “N”, “Nhat” “n” deprecated. Now “count”, “abundance.est” “density.est” allowed. Make predict.dsm work tibbles .set column newdata (error thrown previous code’s check ). Thanks Dave Fifield reporting issue. Fix bug inconsistent predictions density.est used response. Code predict.dsm simplified documentation updated. Thanks Dave Fifield reporting issue. mrds independent observer (io) trial models allowed detection function.Variance can estimated via dsm_varprop (usual limitation covariates may vary segment level) dsm.var.gam. feature currently experimental. Thanks Doug Sigourney Megan Ferguson help suggestions. See ?“dsm-data” information set data. example multiddf mrds analysis dsm https://github.com/densitymodelling/nefsc_fin_mrds_dsm availability= argument now works differently count models. availability must now length number segments (nrow(segment.data)) multiply offset (effective area) rather number animals observed coherent detectability handled case. dsm_varprop longer requies newdata supplied. newdata isn’t present just refitted original models returned, entries NA.","code":""},{"path":"/news/index.html","id":"dsm-230","dir":"Changelog","previous_headings":"","what":"dsm 2.3.0","title":"dsm 2.3.0","text":"CRAN release: 2020-04-22 fixed dsm_varprop (gam.fixed.priors) response distributions fixed scale parameters. Negative binomial results now may incorrect!","code":""},{"path":"/news/index.html","id":"dsm-2218","dir":"Changelog","previous_headings":"","what":"dsm 2.2.18","title":"dsm 2.2.18","text":"Clarification predict.dsm return documentation. Thanks Dave Fifield suggestion. .set=NULL lead predictions 0 density used. Now just returns density. Thanks Dave Fifield catch.","code":""},{"path":"/news/index.html","id":"dsm-2217","dir":"Changelog","previous_headings":"","what":"dsm 2.2.17","title":"dsm 2.2.17","text":"CRAN release: 2019-01-19 Now Suggests package “sp” (needed parts mexdolphin example data)","code":""},{"path":"/news/index.html","id":"dsm-2216","dir":"Changelog","previous_headings":"","what":"dsm 2.2.16","title":"dsm 2.2.16","text":"CRAN release: 2018-06-27 check Sample.Labels match , none throw error. Thanks Madhura Davate bringing issue attention. gamma option removed, since now ignored gam(). using method=“GCV.Cp” gamma=1.4 still used (generally advise using REML rather GCV smoothing parameter selection) dsm now requires mgcv version 1.8-23 higher. dsm.var.prop (dsm_varprop) now throw error covariates detection function can’t anything useful new function obs_exp diagnostic function compare observed expected counts different covariate aggregations","code":""},{"path":"/news/index.html","id":"dsm-2215","dir":"Changelog","previous_headings":"","what":"dsm 2.2.15","title":"dsm 2.2.15","text":"CRAN release: 2017-07-03 mexdolphins loaded using data(), data longer need attach()ed dsm.var.prop throws error count N used response. dsm.var.prop now calls dsm_varprop, keeps scale parameter constant refitting models variance propagation. dsm_varprop provides lower-level interface variance propagation probably faster flexible. add vis.concurvity visually assess concurvity (colinearity extended smooth terms) model new model diagnostic function: plot_pred_by_term – plots effect smooth model spatially. remove “abundance” option response, use “count” dsm.var.prop dsm_varprop better diagnostics checking variance model hasn’t done something weird dsm.var.movblk discards replicates model didn’t converge fix potential issue negative binomial response used variance propagation (due scale parameterisations). dsm_varprop now refits nb() models negbin() advise users look deeply. Thanks Eric Rexstad spotting . fix bug predict.dsm() predictions “density” response including offset. Thanks Len Thomas spotting .","code":""},{"path":"/news/index.html","id":"dsm-2214","dir":"Changelog","previous_headings":"","what":"dsm 2.2.14","title":"dsm 2.2.14","text":"CRAN release: 2017-01-26 nasty bug predict.dsm fixed: logging offset twice newdata provided, leading odd checking plots. also effected results predict() newdata= specified. Thanks Megan Ferguson alerting us . add support point transects(!) rqgam.check() now produced linear predictor vs. randomised quantile residuals plot avoid confusion interpreting plots REML now default method smoothing parameter selection","code":""},{"path":"/news/index.html","id":"dsm-2213","dir":"Changelog","previous_headings":"","what":"dsm 2.2.13","title":"dsm 2.2.13","text":"CRAN release: 2016-10-03 dsm.var.gam now example dsm.var.prop now checks detection function model covariates","code":""},{"path":"/news/index.html","id":"dsm-2212","dir":"Changelog","previous_headings":"","what":"dsm 2.2.12","title":"dsm 2.2.12","text":"CRAN release: 2016-08-10 alpha argument now works analytical variance reported using dsm.var.prop dsm.var.gam print.summary summary methods. Thanks Jason Roberts Eric Rexstad spotting issue. dsm now uses numDeriv::grad calculate derivatives variance estimation – much faster. Thanks Jason Roberts fix. dsm now requires mrds version 2.1.15 higher, due internal changes fixed issue Effort column required even segment.area specified. Thanks Greg Lollback spotting issue. ensured ordering segments matched ordering observations aggregation observations correct. Thanks Dave Fifield reporting bug suggesting fix. check.cols longer checks see column called “distance” strip transects used","code":""},{"path":"/news/index.html","id":"dsm-2211","dir":"Changelog","previous_headings":"","what":"dsm 2.2.11","title":"dsm 2.2.11","text":"dsm.var.prop uses update() rather messing around eval() print.summary.dsm.var didn’t work GAM variance detection function specified, now fixed (thanks Natalia Dellabianca spotting ) Removed non-working plot() code variance examples – see Mexico pantropical spotted dolphins proper treatment plotting using projections (http://distancesampling.org/R/vignettes/mexico-analysis.html) plot.var.gam longer crashes default distance data doesn’t columns “x” “y”","code":""},{"path":"/news/index.html","id":"dsm-2210","dir":"Changelog","previous_headings":"","what":"dsm 2.2.10","title":"dsm 2.2.10","text":"corrected offsets examples dsm, dsm.var.prop, dsm.var.movblk updated mexdolphins data lat/long reversal prediction data non-list storage stopped use rqgam.check used non-negbin/Tweedie responses (thanks Phil Bouchet highlighting issue).","code":""},{"path":"/news/index.html","id":"dsm-229","dir":"Changelog","previous_headings":"","what":"dsm 2.2.9","title":"dsm 2.2.9","text":"CRAN release: 2015-07-29 Moving block bootstrap now works detection function (suggested Laura Williamson) Mexico dolphin data areas prediction grids segments re-projected. Thanks Phil Bouchet pointing error. Context: https://groups.google.com/d/msg/distance-sampling/oj1j8mSmnTc/3cOAAJgBw9MJ","code":""},{"path":"/news/index.html","id":"dsm-228","dir":"Changelog","previous_headings":"","what":"dsm 2.2.8","title":"dsm 2.2.8","text":"Speed reduced memory usage variance calculations, thanks Filipe Dias asking . Better error observations matched detection function. Thanks Ricardo Lima highlighting . Check missing columns incorrect logic, now corrected tests. Thanks Julia Migné spotting .","code":""},{"path":"/news/index.html","id":"dsm-227","dir":"Changelog","previous_headings":"","what":"dsm 2.2.7","title":"dsm 2.2.7","text":"Plotting check plots using random quantile residuals (rqgam.check) didn’t work Tweedie tw family models, now fixed. Thanks Laura Mannocci Jason Roberts pointing . Plotting CV used matrix() coerce data data.frame – thus converting elements simplest type. Errors ensued. Thanks Adrian Schiavini finding bug!","code":""},{"path":"/news/index.html","id":"dsm-226","dir":"Changelog","previous_headings":"","what":"dsm 2.2.6","title":"dsm 2.2.6","text":"dsm.var.prop dsm.var.gam now allow supply single number offset, copy many times need. Thanks Filipe Dias suggesting .","code":""},{"path":"/news/index.html","id":"dsm-225","dir":"Changelog","previous_headings":"","what":"dsm 2.2.5","title":"dsm 2.2.5","text":"CRAN release: 2014-09-16 dsm.var.prop now throw error detection function dsm ’s trying calculate variance (thanks Adrián Schiavini finding ) variance/CV plotting threw error detection function supplied observation=TRUE. Now error sidestepped (, thanks Adrián Schiavini finding ).","code":""},{"path":"/news/index.html","id":"dsm-224","dir":"Changelog","previous_headings":"","what":"dsm 2.2.4","title":"dsm 2.2.4","text":"CRAN release: 2014-06-17 changed stop() warning() data detection function included observation data frame, automatically excluded later, bug found Eric Rexstad Anna Cucknell","code":""},{"path":"/news/index.html","id":"dsm-223","dir":"Changelog","previous_headings":"","what":"dsm 2.2.3","title":"dsm 2.2.3","text":"CRAN release: 2014-04-23 moving block boostrap using observed abundances residuals therefore gave wrong answers (Eric Rexstad found bug)","code":""},{"path":"/news/index.html","id":"dsm-222","dir":"Changelog","previous_headings":"","what":"dsm 2.2.2","title":"dsm 2.2.2","text":"version number reporting now works (Len Thomas found bug) documentation default density presence models now weighted area segment","code":""},{"path":"/news/index.html","id":"dsm-221","dir":"Changelog","previous_headings":"","what":"dsm 2.2.1","title":"dsm 2.2.1","text":"switch new testthat spec added new response variables (Dhat, density.est, count, n), suggestion Len Thomas","code":""},{"path":"/news/index.html","id":"dsm-214","dir":"Changelog","previous_headings":"","what":"dsm 2.1.4","title":"dsm 2.1.4","text":"check observed distances within width now throw error","code":""},{"path":"/news/index.html","id":"dsm-213","dir":"Changelog","previous_headings":"","what":"dsm 2.1.3","title":"dsm 2.1.3","text":"CRAN release: 2013-08-20 CRAN-compatibility fixes","code":""},{"path":"/news/index.html","id":"dsm-212","dir":"Changelog","previous_headings":"","what":"dsm 2.1.2","title":"dsm 2.1.2","text":"updates dsm.cor unified plotting variance estimation tweaks non-dsm models","code":""},{"path":"/news/index.html","id":"dsm-206","dir":"Changelog","previous_headings":"","what":"dsm 2.0.6","title":"dsm 2.0.6","text":"removed warning () comparison length make.soapgrid need pass bnd list() dsm.cor now handles gamm objects dsm.cor allows one check residual autocorrelation models presence/absence data now longer needs dummy detection function object","code":""},{"path":"/news/index.html","id":"dsm-205","dir":"Changelog","previous_headings":"","what":"dsm 2.0.5","title":"dsm 2.0.5","text":"started NEWS file fixed bug dsm.var.gam() didn’t return predictions plotting result fail silly typo docs check ’re using mgcv version >= 1.7-24 GAMM fitting warn ","code":""}]
